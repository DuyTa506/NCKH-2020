\documentclass[12pt, a4paper,oneside]{book}
\usepackage{amsmath, amssymb, latexsym, amscd, amsthm,amstext}  % Typical maths resource packages
\usepackage{graphics}                                           % Packages to allow inclusion of graphics
\usepackage{color} 
\usepackage{varwidth}                                             % For creating coloured text and background
\usepackage{hyperref}                                           % For creating hyperlinks in cross references
\usepackage[utf8]{vietnam}									%For writting Vietnamese
\usepackage{anysize}											% to set the margin size 
\marginsize{3cm}{2cm}{2cm}{2cm}				%\marginsize{left}{right}{top}{bottom}
%\papersize{width}{height}										% sets the paper size
\title{Sections and Chapters}
 \usepackage{multicol}
 \usepackage{wrapfig}  
\usepackage{enumerate}
\usepackage{dsfont}
\usepackage{commath}

\renewcommand{\baselinestretch}{1.3} 
\renewcommand{\figurename}{\bf Hình}

%%========================================
\newtheorem{theo}{\bf Định lý}[section]
\newtheorem{coro}[theo]{\bf Corollary}
\newtheorem{lemm}[theo]{\bf Bổ đề}
\newtheorem{prop}[theo]{\bf Mệnh đề}
\newtheorem{algo}[theo]{\bf Algorithm}
\newtheorem{conj}[theo]{\bf Conjecture}

\theoremstyle{definition}
\newtheorem{dn}[theo]{Định nghĩa}
\newtheorem{dl}[theo]{Định lý}
\newtheorem{tc}[theo]{Tính chất}
\newtheorem{vd}[theo]{\it Ví dụ}
\newtheorem{cy}[theo]{\it Chú ý}
\newtheorem{nx}[theo]{\it Nhận xét}
\newtheorem{pt}{\it Phân tích}



\def\R{\mathbb{ R}}
\def\C{\mathbb{ C}}
\def\N{\mathbb{ N}}
\def\Z{\mathbb{ Z}}
\def\Q{\mathbb{ Q}}
\def\K{\mathbb{ K}}
\def\Sy{\mathbb{ S}}
\def\H{\mathbb{ H}}
\def\T{\mathbb{ T}}
\def\K{\mathbb{ K}}
\def\E{\mathbb{ E}}
\def\Po{\mathbb{ P}}
\def\L{\mathbb{ L}}
\def\qfun{\textsf{q}}
%=========================================
\def\rk{\mbox{\rm \texttt{rank}}}
\def\tr{\mbox{\rm \texttt{Tr}}}  
\def\diag{\mbox{\rm \texttt{diag}}}
\def\re{\mbox{\rm \texttt{Re}}}
\def\im{\mbox{\rm \texttt{Im}}}
\def\face{\mbox{\rm \texttt{face}}}
\def\ran{\mbox{\rm \texttt{Ran}}}
\def\nul{\mbox{\rm \texttt{Nul}}}   
\def\vect{\mbox{\rm \texttt{vec}}}
\def\svec{\mbox{\rm \texttt{svec}}}
\def\sp{\mbox{\rm \texttt{Span}}}
\newcommand{\seq}[1]{\left<#1\right>}
\makeatletter
\def\ps@myheadings{%
\def\@evenhead{\hfil\thepage\hfil}
\def\@oddhead{\hfil\thepage\hfil}}
\makeatother 
\usepackage{anysize}
\marginsize{3cm}{2.5cm}{2cm}{2cm}
\marginsize{3cm}{2.5cm}{2cm}{2cm}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\rank}{rank}
\pagestyle{myheadings}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
%=======================

\DeclareUnicodeCharacter{2212}{-}
\setlength{\parindent}{1 cm}
\usepackage{cases}
\usepackage{graphicx}
%=======================

\begin{document}
\begin{center}
	\textbf{{\normalsize KHOA TOÁN VÀ THỐNG KÊ}}\\
	\vspace{3cm}
	\textbf{{\LARGE DEMO}}\\
	\vspace{2.5cm}
	\textbf{{\normalsize BÁO CÁO TỔNG KẾT\\
			ĐỀ TÀI NGHIÊN CỨU KHOA HỌC SINH VIÊN\\
			THAM GIA XÉT GIẢI THƯỞNG\\
			SINH VIÊN NGHIÊN CỨU KHOA HỌC CẤP TRƯỜNG}}
		
		
		\vspace{2.5cm}
\textbf{{\large NGHIÊN CỨU VỀ PHÂN TÍCH CHUỖI THỜI GIAN BẰNG MÔ HÌNH ARIMA VỚI PHẦN MỀM R}}\\
\vspace{2.5cm}

           \textbf{	{\normalsize CAO THỊ ÁI LOAN\\
           		PHÙNG THỊ HỒNG DIỄM\\
           		LÊ PHƯƠNG THẢO\\
           		ĐINH THỊ QUỲNH NHƯ\\
           		NGUYỄN QUỐC DƯƠNG }}\\
           \vspace{1cm}
            \textbf{ Người hướng dẫn: TS. Lê Thanh Bính}
            
            
\end{center}
\tableofcontents

\chapter{Tổng quan về lý thuyết chuỗi thời gian và mô hình ARIMA}

Trong chương 1, chúng tôi sẽ...

\section{Các vấn đề về chuỗi thời gian}

Chuỗi thời gian (tiếng Anh: time series) trong thống kê, xử lý tín hiệu, kinh tế lượng và toán tài chính là một chuỗi các điểm dữ liệu, được đo theo từng khoảng khắc thời gian liền nhau theo một tần suất thời gian thống nhất. Nghiên cứu chuỗi thời gian luôn là một bài toán gây được sự chú ý của các nhà toán học, kinh tế học, xã hội học, khí tượng và khí hậu học, … Các quan sát trong thực tế thường được thu thập dưới dạng chuỗi số liệu. Từ những chuỗi số liệu này, người ta có thể trích xuất ra được các thuộc tính thống kê có ý nghĩa và các đặc điểm của dữ liệu. Nhưng ứng dụng quan trọng nhất là dự báo, đánh giá được khả năng xảy ra khi cho một chuỗi số liệu. 
\subsection{Các yếu tố phụ phuộc}
Tự tương quan và tương quan chéo

Mô tả đầy đủ của một chuỗi thời gian, được quan sát như một tập hợp của n biến ngẫu nhiên tại các thời điểm tùy ý $t_{1},t_{2},...t_{n}$ (với n là số nguyên dương bất kỳ),được cho bởi hàm phân phối chung, với xác suất các giá trị trong dãy đều nhỏ hơn các hằng số $c_{1},c_{2},..c_{n},$ tức là:
$$F(c_{1},c_{2},...,c_{n})= P(x_{t1}\leq c_{1},x_{t2}\leq c_{2},...,x_{tn}\leq c_{n}).$$ 

Thật không may, hàm phân phối nhiều chiều thường không viết được dễ dàng, trừ khi các biến ngẫu nhiên đạt chuẩn chung, trong trường hợp đó, biểu thức $(1.8)$ xuất phát từ phân phối chuẩn nhiều chiều (xem Anderson, 1984,hoặc Johnson và Wicotta, 1992).Một trường hợp cụ thể trong đó hàm phân phối nhiều chiều được biểu diễn dễ dàng nếu các biến chuẩn độc lập ngẫu nhiên và phân phối giống hệt nhau, trong đó hàm phân phối chung có thể được biểu thị là giá trị trên biên,
$$F(c_{1},c_{2},...,c_{n})= \Pi \Phi(c_{t}),$$
với mọi $$\Phi(x) = \dfrac{1}{\sqrt{2\pi}} \int_{-\infty}^{x} exp -\dfrac{z^2}{2} dx $$
là hàm phân phối tích lũy của  phân phối thông thường.
Mặc dù phân phối đa chiều có thể mô tả được hoàn toàn các dữ liệu , nhưng nó là một công cụ khó sử dụng để hiển thị và phân tích dữ liệu chuỗi thời gian. Hàm phân phối $(1.8)$ phải được đánh giá là hàm của n đối số, vì vậy biểu đồ bất kỳ của hàm mật độ nhiều chiều tương ứng là hầu như không khả thi. Hàm phân phối một chiều
$${F}_{t}(x)= {P}\{x_{t}\leq x\}$$
hoặc các hàm mật độ một chiều tương ứng
$${f}_{t}(x)= \dfrac{\delta{F}_{t}(x)}{\delta(x)}$$
khi chúng tồn tại, thường cung cấp thông tin để xác định xem liệu một toạ độ nào đó của chuỗi thời gian có hàm mật độ  giống như phân phối (Gaussian) thông thường hay không.
\begin{dn}\textbf{Hàm trung bình} được định nghĩa là
	$$ \mu_{xt} = E(x_{t}) =  \int_{-\infty}^{\infty} xf_{t}(x)  dx $$
	tồn tại, trong đó $E$ là toán tử kỳ vọng thường. Khi không có sự nhầm lẫn nào về chuỗi thời gian mà chúng ta đang xét, chúng ta sẽ bỏ đi chỉ số dưới và viết tắt $\mu_{xt}$ là $\mu_{t}$.
	Điều quan trọng để thực hiện $\mu_{t}$ là nó có ý nghĩa lý thuyết cho chuỗi tại một thời điểm cụ thể, trong đó giá trị trung bình được áp dụng cho tất cả các trường hợp có thể có thể tạo ra $x_{t}$.
\end{dn}
\begin{vd}\textbf{Hàm trung bình của chuỗi trượt trung bình}
	Nếu $w_{t}$ biểu thị một chuỗi nhiễu trắng, thì $w_{t} = E (w_{t}) = 0$ với mọi t. Chuỗi trên cùng trong Hình 1.8 thể hiện điều này, vì rõ ràng chuỗi dao động xung quanh giá trị trung bình bằng không. Làm mịn chuỗi như trong ví dụ 1.9 không thay đổi giá trị trung bình vì chúng ta có thể viết
	$$\mu_{vt}= E(v_{t})=\dfrac{1}{3}[E(w_{t-1})+ E(w_{t})+ E(w_{t+1})].$$
\end{vd}
\begin{vd}\textbf {Hàm trung bình của bước ngẫu nhiên với hằng số}
	Hãy xem xét bước ngẫu nhiên với hằng sốđược đưa ra trong (1.4),
	$$ x_{t} = \delta t + \sum_{j=1}^{t} w_{j}, t= 1,2,..$$
	Như trong ví dụ trước, vì $E(w_{t}) = 0$ với mọi t và là hằng số, chúng ta có
	$$\mu_{xt} = E(x_{t}) = \delta t + \sum_{j=0}^{t} E (w_{j}) = \delta t$$
	là đường thẳng với độ dốc $\mu$. Thực hiện của bước ngẫu nhiên với hằng số có thể được so sánh với hàm trung bình của nó trong hình 1.10.
\end{vd}
\begin{vd}\textbf{Hàm trung bình của mô hình cộng tính}
	Rất nhiều ứng dụng thực tế phụ thuộc vào giả định quan sátdữ liệu đã được tạo bởi một dạng sóng tín hiệu cố định được đặt chồng lên trênquá trình nhiễu trung bình bằng không, dẫn đến một mô hình tín hiệu cộng tính với dạng(1.5). Rõ ràng, vì tín hiệu trong (1.5) là một hàm cố định theo thời gian,chúng ta sẽ có
	$$\mu_{xt} = E(x_{t}) = E [2cos(\dfrac{2\pi t}{50} + .6\pi) + \omega_{t}] = 2 cos(\dfrac{2\pi t}{50} +.6\pi) + E(\omega_{t})) = 2 cos (\dfrac{2\pi t}{50} + .6\pi)$$
	và hàm trung bình chỉ là \textbf{sóng cosin}.
\end{vd}
Sự thiếu độc lập giữa hai giá trị liền kề $x_{s}$ và $x_{t}$ có thể là đánh giá bằng số, như trong thống kê cổ điển, sử dụng các khái niệm hiệp phương saivà tương quan. Giả sử phương sai của $x_{t}$ là hữu hạn, chúng ta có định nghĩa sau
\begin{dn}\textbf{Hàm tự hiệp phương sai}
	được định nghĩa là tích số mômen cấp hai
	$$\gamma_{x}(s,t) = E [(x_{s} - \mu_{t})],$$
	cho tất cả s và t. Khi không có sự nhầm lẫn nào về chuỗi thời gian chúng ta đang xét, chúng ta sẽ bỏ chỉ số dưới và viết $\gamma_{x}(s,t)$ là $ \gamma_{s,t}.$
	Lưu ý rằng $\gamma_{x}(s,t) =\gamma_{x}(t,s)$ được áp dụng cho tất cả các điểm thời gian s và t. Độ đo của tự hiệp phương sai phụ thuộc tuyến tính giữa hai điểm trên cùng một chuỗi được quan sát tại thời điểm khác nhau. Chuỗi trơn thể hiện hàm tự hiệp phương sai vẫn lớn ngay cả khi t và s cách xa nhau, trong khi các chuỗi không xác định choppy có xu hướng có hàm tự hiệp phương sai  gần như bằng 0 đối với các khoảng cách lớn. Tự hiệp phương sai (1.12) là trung bình tích vecto so với mật độ khớp $F=(x_{s}, x_{t})$. Nhớ lại từ thống kê cổ điển rằng nếu $\gamma_{x} (s,t)= 0$, $x_{s}$ và $x_{t}$ là không liên quan tuyến tính, nhưng vẫn có thể có một số cấu trúc phụ thuộc giữa chúng. Tuy nhiên, nếu $x_{s}$ và $x_{t}$ các biến 2 chiều, $\gamma_{x}(s,t) = 0$ đảm bảo sự độc lập giữa chúng. Rõ ràng là, với s = t, tự hiệp phương sai giảm (giả định hữu hạn) , bởi vì
	$$\gamma_{x}(t,t) = E [(x_{t}- \mu_{t})^2]$$
\end{dn}
\begin{vd}\textbf{Tự hiệp phương sai của nhiễu trắng}
	Chuỗi nhiễu trắng wt, được hiển thị trong bảng trên cùng của Hình 1.8, có\\ $E(\omega_{t}) =0$ và $$\gamma_{\omega}(s,t) = E (\omega_{s}\omega_{t}) = $$
	trong ví dụ này, $\delta^2_{\omega} = 1$. Lưu ý rằng $\omega_{s}$ và $\omega_{t}$ không tương quan với $s \neq t$, chúng ta sẽ có $E(w_{s}w_{t}) =E(w_{s})E(w_{t}) = 0$ vì giá trị trung bình của các biến thiên nhiễu trắng bằng không.
\end{vd}
\begin{vd}\textbf{Tự hiệp phương sai trung bình trượt}	
	Xem xét áp dụng trung bình trượt  ba điểm cho chuỗi nhiễu trắng $w_{t}$ của ví dụ trước, như trong ví dụ 1.9 $(\delta_{w}^{2} = 1)$. Vì $v_{t}$ trong(1.1) có nghĩa là không, chúng ta có
	$$ \gamma_{v}(s,t) = E [(v_{s}-0)(v_{t}-0)] = \dfrac{1}{9}E[(w_{s-1}+ w_{s} +w_{s+1})(w_{t-1}+w_{t}+ w_{t+1})].$$
	Thật thuận tiện khi tính toán nó như là một hàm của sự phân tách, $s - t = h$,giả sử, với $h = 0, \pm 1, \pm 2 ,...$ Ví dụ: với $h = 0$, 
	$$ \gamma_{v}(t,t)= \dfrac{1}{9}E[(w_{t-1}+ w_{t} +w_{t+1})(w_{t-1}+w_{t}+ w_{t+1})]= \dfrac{1}{9}[E(w_{t-1} w_{t-1} +E(w_{t})(w_{t})+ E(w_{t+1}w_{t+1})] = \dfrac{3}{9}.$$
	Khi $h=1$ 
	$$ \gamma_{v}(t+1,t) = \dfrac{1}{9}E[(w_{t} + w_{t+1} + w_{t+2})(w_{t-1} + w_{t}+ w_{t+1})] =\dfrac{1}{9}[E(w_{t} w_{t} + E(w_{t+1}w_{t+1})] = \dfrac{2}{9} .$$ 
	Thực tế có thể giúp chúng ta giảm thấp số hạng với chỉ số dưới không cân bằng. Tính toán tương tự cho  $\gamma_{v}(t-1,t)= \dfrac{2}{9},\gamma_{v}(t+2,t) = \gamma_{v}(t-2,t)=\dfrac{1}{9} $, và 0 cho các khoảng cách lớn hơn. Chúng ta tóm tắt các giá trị cho tất cả s và t là 
	\begin{align*}
	\gamma_{v}(s,t) 
	\begin{cases}  \dfrac{3}{9}, s=t \\
	\dfrac{2}{9}, \textbar {s-t} \textbar = 1\\
	\dfrac{1}{9}, \textbar {s-t} \textbar = 2\\
	0, \textbar {s-t} \textbar \geq 3 
	\end{cases}
	\end{align*}
\end{vd}

Ví dụ 1.17 chứng tỏ rõ ràng phép toán làm trơn đưa vào hàm hiệp phương sai giảm khi khoảng cách giữa hai điểm thời giantăng và biến mất hoàn toàn khi các điểm thời gian được phân tách bằngba hoặc nhiều điểm thời gian. Tự hiệp phương sai rất thú vị vì nó chỉ phụ thuộc vào sự phân tách thời gian hoặc độ trễ chứ không phụ thuộc vào sự tuyệt đối về vị trí của các điểm dọc theo chuỗi. Sau này chúng ta sẽ thấy rằng sự phụ thuộc này cho thấy một mô hình toán học cho các khái niệm về tính dừng yếu.
\begin{dn}\textbf{Hàm tự tương quan (ACF)} được định nghĩa là
	$$\rho(s,t) = \dfrac{\gamma(s,t)}{\sqrt{\gamma(s,s)\gamma(t,t)}}$$
\end{dn}

AFC đo lường khả năng dự đoán tuyến tính của chuỗi tại thời điểm t, giả sử, $x_t$, chỉ sử dụng giá trị $x_s$. Chúng ta có thể dễ dàng chỉ ra rằng $-1 \le (s,t)\le 1$ bằng cách sử dụng bất đẳng thức Cauchy Schwars. Nếu chúng ta có thể dự đoán $x_t$ hoàn hảo từ $x_s$ thông qua quan hệ tuyến tính, $x_t=\beta_0+\beta_1 x_s$, thì tương quan sẽ là 1 khi $\beta_1>0$ và $-1$ khi $\beta_1<0$. Do đó, chúng tôi có một thước đo sơ bộ về khả năng dự báo chuỗi tại thời điểm t từ giá trị tại thời điểm s. Thông thường, chúng tôi muốn đo lường khả năng dự đoán của một chuỗi $y_t$ khác từu chuỗi $x_t$. Giả sử cả hai loại có phương sai hữu hạn, chúng ta có
\begin{dn}\textbf{Hàm hiệp phương sai} giữa hai chuỗi $x_{t}$ và $y_{t}$ là $$\gamma_{xy}(s,t) = E[(x_{s}- \mu_{xs})(y_{t}- \mu_{yt})].$$
\end{dn}
Phiên bản thu nhỏ của texrbf{hàm hiệp phương sai} được gọi là
\begin{dn}\textbf{Hàm tương quan chéo (CCF)}
	$$\rho_{xy}(s,t) = \dfrac{\gamma_{xy}(s,t)}{\sqrt{\gamma_{x}(s,s)\gamma_{y}(t,t)}}$$
	Chúng tôi có thể dễ dàng mở rộng các khái niệm trên với trường hợp chuỗi hơn hai, giả sử, $x_{t1}$, $x_{t2}$, ..., $x_{tr}$; đó là, chuỗi thời gian đa biến với các thành phần r. Ví dụ, phần mở rộng của (1.12) trong trường hợp này là
	$$\gamma_{jk}(s,t) = E [(x_{sj}-\mu_{sj})(x_{tk}-\mu_{tk})];   j,k= 1,2,..,r$$
	Trong các định nghĩa ở trên, các hàm tự hiệp phương sai và hiệp phương sai có thể thay đổi khi một bước truợt dọc theo chuỗi vì các giá trị phụ thuộc vào cả s và t, vị trí của các điểm theo thời gian. Trong ví dụ 1.17, hàm tự hiệp phương sai phụ thuộc vào sự phân tách của $x_{s}$ và $x_{t}$, giả sử, $h= \lvert s-t\lvert$, và không phụ thuộc vào vị trí của các điểm trong thời gian. Miễn là các điểm được phân tách bằng đơn vị h, vị trí của hai điểm không quan trọng. Khái niệm này, được gọi là tính dừng yêu. Khi giá trị trung bình không đổi, là cơ bản trong việc cho phép chúng tôi phân tích dữ liệu chuỗi thời gian mẫu khi chỉ có một chuỗi duy nhất.
\end{dn}
\subsection{Chuỗi thời gian dừng}
	Các định nghĩa trước của hàm trung bình và hàm tự hiệp phương sai hoàn toàn chung. Mặc dù chúng tôi chưa đưa ra bất kỳ giả định đặc biệt nào về hành vi của chuỗi thời gian, nhiều ví dụ trước đã gợi ý rằng một điểm tính chất đều đặn có thể tồn tại theo thời gian trong hành vi của chuỗi thời gian. Chúng tôi giới thiệu khái niệm về tính đều đặn bằng cách sử dụng một khái niệm gọi là tính dừng. 
\begin{dn}
	\textit{Một chuỗi dừng ngặt} là một chuỗi trong đó hành vi xác suất của mọi tập hợp các giá trị
	$$ \left\lbrace x_{t_{1}}, x_{t_{2}}, ..., x_{t_{k}}\right\rbrace $$
	là giống hệt với bộ thời gian thay đổi
	$$ \left\lbrace x_{t_{1}+h}, x_{t_{2}+h}, ..., x_{t_{k}+h}\right\rbrace  $$
	
	Đó là 
	$$P\left\lbrace x_{t_{1}}\le c_{1},...,x_{t_{k}}\le c_{k}\right\rbrace = P\left\lbrace x_{t_{1}+h}\le c_{1},...,x_{t_{k}+h}\le c_{k}\right\rbrace$$
	Với mọi $k=1,2,...$ ,tất cả các điểm thời gian $t_{1},t_{2},...,t_{k}$, tất cả các số $c_{1},c_{2},...,c_{k}$ và tất cả các lần dịch chuyển $h=0,\pm1,\pm2$,...
	
\end{dn}

Nếu một chuỗi thời gian là dừng, thì tất cả các hàm phân phối nhiều biến cho các tập hợp con của biến đó phải phù hợp với các đối tác của chúng trong tập dịch chuyển cho tất cả các giá trị của tham số dịch chuyển $h$. 
Ví dụ: khi $k = 1$, (1.19) ngụ ý rằng
$$P\left\lbrace x_{s} \le  c \right\rbrace = P\left\lbrace x_{t} \le  c \right\rbrace $$ 

cho mọi thời điểm $s$ và $t$. Tuyên bố này ngụ ý, ví dụ, xác suất giá trị của chuỗi thời gian được lấy mẫu hàng giờ là âm vào lúc 1 giờ sáng giống như lúc 10 giờ sáng. Ngoài ra, nếu hàm trung bình, $\mu_{t}$ của chuỗi $x_{t}$ tồn tại (1.20) ngụ ý rằng $\mu_{}$ = $\mu_{t}$ cho tất cả s và t, và do đó t phải là hằng số. Lưu ý, ví dụ, quy trình bước ngẫu nhiên với hằng số không hoàn toàn đứng yên vì hàm trung bình của nó thay đổi theo thời gian.

khi $k=2$ chúng ta có thể viết ... là
$$P\left\lbrace x_{s}\le c_{1},x_{t}\le c_{2}\right\rbrace = P\left\lbrace x_{s+h}\le c_{1},x_{t+h}\le c_{2}\right\rbrace$$
cho bất kỳ thời điểm nào $ s $ và $ t $ và thay đổi $ h $. Do đó, nếu hàm phương sai của quá trình tồn tại, ... ngụ ý rằng hàm tự động điều khiển của chuỗi $x_{t}$ thỏa mãn :$$\gamma(x,t)=\gamma(s+h,t+h) $$
với tất cả $s$ và $t$ và $h$. Chúng tôi có thể giải thích kết quả này bằng cách nói hàm tự hiệp phương sai của quá trình chỉ phụ thuộc vào chênh lệch thời gian giữa $s$ và $t$, và không dựa trên thời gian thực tế. Phiên bản của tính dừng trong (1.19) quá mạnh đối với hầu hết các ứng dụng. Hơn nữa, rất khó để đánh giá sự ổn định nghiêm ngặt từ một tập dữ liệu duy nhất. Thay vì áp đặt các điều kiện cho tất cả các phân phối có thể có của một chuỗi thời gian, chúng tôi sẽ sử dụng một phiên bản nhẹ hơn, chỉ áp dụng các điều kiện trong hai thời điểm đầu tiên của chuỗi. Bây giờ chúng ta có định nghĩa sau
\begin{dn}	
	\textit{Tính dừng yếu của một chuỗi thời gian} , $x_{t}$ ,là một sai phân hữu hạn sao cho
	
	(i) hàm giá trị trung bình, $\mu_{t}$, được xác định trong (1.11) là hằng số và không phụ thuộc vào thời gian $t$, và
	
	(ii) hàm hiệp phương sai, $ \gamma(s, t)$, được xác định trong (1.12) chỉ phụ thuộc vào $s$ và $t$
	thông qua sự khác biệt của họ $ \abs{s-t} $
	
\end{dn}

Do đó, chúng tôi sẽ sử dụng thuật ngữ tính dừng có nghĩa là tính dừng yếu; nếu một quá trình dừng theo nghĩa chặt chẽ, chúng tôi sẽ sử dụng thuật ngữ tính dừng ngặt.

Cần phải rõ ràng trong nghiên cứu về tính dừng ngặt theo Định nghĩa 1.6 rằng một phương sai ổn định, hữu hạn, chuỗi thời gian cũng dừng. Điều ngược lại là không đúng trừ khi có thêm điều kiện. Một trường hợp quan trọng khi tính dừng nghiêm ngặt là nếu chuỗi thời gian Gaussian [nghĩa là tất cả các bản phân phối hữu hạn, (1,19), của chuỗi là Gaussian].Chúng tôi sẽ làm cho khái niệm này chính xác hơn vào cuối phần này

Bởi vì hàm trung bình, $E(x_{t})=\mu_{t}$, của chuỗi dừng làđộc lập với thời gian $t$, chúng tôi sẽ viết $$\mu_{t}=\mu$$

Ngoài ra, vì hàm hiệp phương sai của một chuỗi thời gian đứng yên, $ \gamma(s, t)$, chỉ dừng lại ở $s$ và $t$,thông qua sự khác biệt của chúng $ \abs{s-t} $, chúng tôi có thể đơn giản hóaviệc phân bổ. Đặt $s = t + h$, trong đó $h$ đại diện cho sự thay đổi thời gian hoặc độ trễ, sau đó
\begin{align*}
\gamma(s, t)&= \E[(x_{t+h}-\mu)(x_{t}-\mu)]\\
&=\E[(x_{h}-\mu)(x_{0}-\mu)]\\
&=\gamma(h,0).
\end{align*}

không phụ thuộc vào đối số thời gian $t$; chúng tôi đã giả sử rằng $var(x_{t}) =\gamma(0,0) < \infty $ .Do đó, để thuận tiện, chúng tôi sẽ bỏ đối số thứ hai

\begin{dn}
	Hàm tự hiệp phương sai của chuỗi dừng sẽ được viết dưới dạng: 
	
	$$\gamma(h)= \E[(x_{t+h}-\mu)(x_{t}-\mu)]$$
	
\end{dn}
\begin{dn}
	Hàm tự tương quan (ACF) của chuỗi dừng sẽ được viết bằng cách sử dụng (1.15) như
	$$\rho(h)=\frac{\gamma(t+h,t)}{\sqrt{\gamma(t+h,t+h)\gamma(t,t)}}$$
\end{dn}

Bất đẳng thức Cauchy Schwarzmột lần nữa cho thấy rằng $−1\leqslant \rho(h) \leqslant 1$ với tất cả $h$, cho phép đánh giá tầm quan trọng tương đối của một giá trị tự tương quan nhất định bằng cách so sánh với các giá trị cực trị −1 và 1.

Hàm tự hiệp phương sai của một quá trình dừng có một số thuộc tính hữu ích. Đầu tiên, giá trị tại $h = 0$, cụ thể là
$$\gamma(0)=E[(x_{t}-\mu)^{2}]$$
là phương sai của chuỗi thời gian; lưu ý rằng bất đẳng thức Cauchy Schwarz ngụ ý
$$ \abs{\gamma(h)}\leqslant \gamma(0)$$
Một thuộc tính hữu ích cuối cùng, được lưu ý trong ví dụ trước, là hàm tự hiệp phương sai của một chuỗi  là đối xứng xung quanh gốc, nghĩa là,
$$\gamma(h)=\gamma(-h)$$
với tất cả $h$. Thuộc tính này theo sau bởi vì dịch chuyển chuỗi theo $h$ có nghĩa là
\begin{align*}
\gamma(h)&=\gamma(t+h-t) \\
&=\E[(x_{t+h}-\mu)(x_{t}-\mu)]\\
&=\E[(x_{t}-\mu)(x_{t+h}-\mu)]\\
&=\gamma(t-(t+h))\\
&=\gamma(-h).
\end{align*}
Trong đó, nó hướng dẫn sử dụng ký hiệu cũng như chứng minh kết quả. Khi một số chuỗi khả thi, một khái niệm về tính dừng vẫn được áp dụng với điều kiện bổ sung

\begin{dn}	
	\textit{Hai chuỗi thời gian, giả sử, $x_{t}$ và $y_{t}$, được cho là cùng dừng nếu mỗi chuỗi là dừng và là hàm hiệp phương sai} 
	$$\gamma_{xy}(h)=E[(x_{t+h}-\mu_{x})(y_{t}-\mu_{y})]$$
	là hàm duy nhất của độ trễ $h$. 
\end{dn}
\begin{dn}	
	\textit{Hàm tương quan chéo (CCF) của chuỗi dừng $x_{t}$ và $y_{t}$ được định nghĩa là} 
	$$\rho_{xy}(h)=\dfrac{\gamma_{xy}(h)}{\sqrt{\gamma_{x}(0)\gamma_{y}(0)}}$$
	
\end{dn}
Một lần nữa, chúng ta có kết quả $−1\leqslant \rho_{xy}(h) \leqslant 1$ cho phép so sánh với các giá trị cực trị −1 và 1 khi xem xét mối quan hệ giữa $x_{t+h}$ và $y_{t}$. Hàm tương quan chéo thỏa mãn 
$$\rho_{xy}(h)=\rho_{xy}(-h)$$
có thể được hiển thị bằng các thao tác tương tự như các thao tác được sử dụng để hiển thị (1.27).

Khái niệm về tính dừng yếu là cơ sở cho hầu hết các phân tích thực hiện với chuỗi thời gian. Các tính chất cơ bản của giá trị trung bình và hàm tự hiệp phương sai (1.22) và (1.24) được thỏa mãn bởi nhiều mô hình lý thuyết có vẻ như tạo ra thực hiện mẫu chính đáng. Trong các ví dụ 1.9 và 1.10, hai chuỗi được tạo ra tạo ra các nhận thức cố định và trong ví dụ 1.20, chúng tôi đã chỉ ra rằng chuỗi trong ví dụ 1.9 trên thực tế là không ổn định. Cả hai ví dụ là các trường hợp đặc biệt của cái gọi là quá trình tuyến tính xuất hiện để tạo ra các nhận thức mẫu hợp lý.
\begin{dn}	
	\textit{Một quy trình tuyến tính, $x_{t}$, được định nghĩa là sự kết hợp tuyến tính của các biến thiên nhiễu trắng $w_{t}$ và được đưa ra bởi} 
	$$ x_{t}=\mu+\sum_{j=-\infty}^{\infty}\psi_{j}\omega_{t-j}  $$ 
	với các hệ số thỏa mãn
	$$ \sum_{j=-\infty}^{\infty}\abs{\psi_{j}}<\infty $$
\end{dn}
Đối với quy trình tuyến tính (xem Bài toán 1.11), chúng tôi có thể chỉ ra rằng hàm tự hiệp phương sai được đưa ra bởi
$$ \gamma(h)=\sigma_{\omega}^2 \sum_{j=-\infty}^{\infty}\psi_{j}+h\psi_{j} $$
Cho $ h\geqslant0 $ , nhớ lại rằng $\gamma(h)=\gamma(-h)$. Phương pháp này thể hiện hàm tự hiệp hương sai của quá trình theo các sản phẩm độ trễ của các hệ số. Ghi chú rằng, ví dụ 1.9, chúng ta có $ \psi_{0}=\psi_{-1}=\psi_{1}=1/3 $ 3 và kết quả trong ví dụ 1.20 xuất hiện ngay lập tức. Chuỗi hồi quy trong ví dụ 1.10 cũng có thể được đặt ở dạng này, cũng như các quy trình hồi quy trung bình trượt chung được xem xét trong Chương 3. 
Cuối cùng, như đã đề cập trước đây, một trường hợp quan trọng trong đó một loạt chuỗi dừng yếu cũng như chuỗi dừng nghiêm ngặt là chuỗi  bình thường hoặc Gaussian.
\begin{dn}
	Một quy trình $ \left\lbrace x_{t}\right\rbrace  $ được gọi là quy trình Gaussian nếu các vectơ $ k $ chiều $ x=\left\lbrace x_{t_{1}}, x_{t_{2}}, ..., x_{t_{k}}\right\rbrace^{'} $ cho mọi tập hợp các điểm thời gian $t_{1},t_{2},...,t_{k}$ và mọi số nguyên dương $ k $, có phân phối chuẩn nhiều chiều.
\end{dn}
Xác định vectơ trung bình $ k \times 1 $, $E(x)\equiv\mu=\left\lbrace \mu_{t_{1}}, \mu_{t_{2}}, ..., \mu_{t_{k}}\right\rbrace^{'}$ và ma trận hiệp phương sai $ k \times k $ , $ cov(x)\equiv\Gamma=\left\lbrace \gamma(t_{i},t_{j});i.j=1,...,k\right\rbrace $
hàm mật độ của phân phối chuẩn nhiều chiều có thể được viết là
$$ f(x)=(2\pi)^{-n/2}\abs{\Gamma}^{-1/2}exp \left\lbrace-1/2(x-\mu)^{'}\Gamma^{-1}(x-\mu)\right\rbrace  $$
ở \abs{\cdot} biểu thị định thức.. Phân phối này tạo cơ sở để giải quyết các vấn đề liên quan đến suy luận thống kê cho chuỗi thời gian. Nếu một chuỗi thời gian Gaussian, $ \left\lbrace x_{t}\right\rbrace  $,tính dừng yếu, thì $ \mu_{t}=\mu $ và $\gamma(t_{i},t_{j})=\gamma(\abs{t_{i}-t_{j}}) $,sao cho vectơ $ \mu $ và ma trận $ \Gamma $ không phụ thuộc vào thời gian. Từ đó suy ra rằng tất cả các phân phối hữu hạn, (1.34), của chuỗi $ \left\lbrace x_{t}\right\rbrace  $ chỉ phụ thuộc vào độ trễ thời gian chứ không phụ thuộc vào thời gian thực tế và do đó, chuỗi phải  dừng nghiêm ngặt . Chúng tôi sử dụng mật độ chuẩn nhiều chiều ở dạng đã cho ở trên cũng như trong phiên bản sửa đổi, áp dụng cho các biến ngẫu nhiên phức tạp trong phần tiếp theo.
\subsection{Ước lượng của tương quan}

Mặc dù lý thuyết các hàm tự tương quan và các hàm tương quan chéo là hữu ích để mô tả các thuộc tính của các mô hình giả thuyết nhất định, hầu hết các phân tích phải được thực hiện bằng cách sử dụng dữ liệu được lấy mẫu. Giới hạn này có nghĩa là các điểm được lấy mẫu $x_ 1$, $x_2$,...,$x_n$   chỉ có sẵn để ước tính giá trị trung bình, hàm tự hiệp phương sai  , và các hàm tự tương quan. Từ quan điểm của thống kê cổ điển, điều này đặt ra một vấn đề bởi vì chúng ta thường sẽ không có các bản sao mẫu ngẫu nhiên của xt có sẵn để ước tính các hàm hiệp phương sai và các hàm tương quan.

Tuy nhiên, trong tình huống thông thường chỉ có một lần thực hiện, giả định về tính dừng trở nên quan trọng. Bằng cách nào đó, chúng ta phải sử dụng trung bình trên thực hiện đơn này để ước tính số bình quân của tổng thể chung và hàm hiệp phương sai.
Theo đó, nếu một chuỗi thời gian là ổn định, hàm trung bình (1.22), $\mu.t=\mu$  là hằng số để chúng ta có thể ước tính nó theo trung bình mẫu
$$ \bar{x} = \frac{1}{n}.\sum _ {i = 1 } ^ { \infty } x_{t} $$
Lý thuyết hàm tự hiệp phương sai được ước tính bằng hàm tự hiệp phương sai mẫu định nghĩa như sau
\begin{dn}
\textit{Hàm tự hiệp phương sai mẫu} được định nghĩa là $$\hat{\gamma}(h) = n^{-1}.\sum _ {t = 1 } ^ {n-h} (x_{t+h}-\bar{x}).(x_{t}-\bar{x})$$	với $\hat{\gamma}(-h) = \hat{\gamma}(h)$ cho $h= 0,1,...,n-1$
\end{dn}
Tổng trong (1.36) chạy trong phạm vi bị giới hạn do $x_{t+h}$ không khả dụng cho $t + h> n$. Công cụ ước tính trong (1.36) thường được ưu tiên cho công cụ ước tính sẽ thu được bằng cách chia cho $n - h$ vì (1.36) là một hàm xác định không âm. Điều này có nghĩa là nếu chúng ta để $\hat{\Gamma}(-h) =\left\lbrace \hat{\gamma}(i-j); i,j=1,...,n\right\rbrace $ là ma trận $n \times n$  hiệp phương sai mẫu của dữ liệu $x = (x_{1}, ..., x_{n})^{'}$ thì $\hat{\Gamma}$ là ma trận xác định không âm. Vì vậy, nếu chúng ta để  $a = (a_{1}, ..., a_{n})^{'}$ là một vectơ $n \times 1$ của hằng số, sau đó $\hat{var}(a'x) = a'\hat{\varGamma}a\geq 0$. Do đó, thuộc tính xác định không âm đảm bảo phương sai mẫu của các tổ hợp tuyến tính của các biến thiên $x_{t}$ sẽ luôn luôn không âm. Lưu ý rằng không chia cho $n$ hay $n - h$ trong (1.36) sẽ không thiên vị ước tính của $\gamma(h)$.

Hàm tự tương quan mẫu được xác định, tương tự như (1.25), như $$\hat{\rho}(h)=\dfrac{\hat{\gamma}(h)}{\hat{\gamma}(0)}$$
Hàm tự tương quan mẫu có phân phối mẫu cho phép chúng tôi để đánh giá liệu dữ liệu đến từ một chuỗi hoàn toàn ngẫu nhiên hay chuỗi trắng hoặc liệu các mối tương quan có ý nghĩa thống kê ở một số độ trễ. Chi tiết chính xác được đưa ra trong Định lý A.7 trong Phụ lục A. Chúng ta có 
\begin{dl}
\textbf{Phân phối mẫu lớn của ACF}\
Trong điều kiện chung, nếu $ x_{t}$ là nhiễu trắng, thì với n lớn, ACF mẫu, $\hat{\rho_{x}}(h)$ với h = 1,2,...,H, trong đó H cố định nhưng tùy ý, xấp xỉ thường được phân phối vói giá trị trung bình bằng 0 và độ lệch chuẩn được cho bởi
$$\sigma_{\hat{\rho_{x}}(h)}=\dfrac{1}{\sqrt{n}}$$
\end{dl}
Dựa trên kết quả trên, chúng tôi có được một phương pháp thô để đánh giá xem
các đỉnh trong $\rho(h)$ có ý nghĩa bằng cách xác định xem đỉnh quan sát được không ngoài khoảng $\pm\dfrac{2}{\sqrt{n}}$ (hoặc cộng / trừ hai lỗi tiêu chuẩn); cho một trình tự nhiễu trắng, khoảng $95$ của  ACF mẫu phải nằm trong số hạn mức này. Các ứng dụng của tính chất này phát triển vì nhiều quy trình thống kê mô hình hóa phụ thuộc vào việc giảm chuỗi thời gian thành chuỗi nhiễu trắng bởi nhiều loại biến đổi. Sau khi trình tự như vậy được áp dụng, đồ thị  ACF của phần còn lại sau đó nên nằm trong giới hạn cho trước ở trên.
\begin{dn}
Các công cụ ước tính cho hàm hiệp phương sai $\gamma xy(h)$, như được cho trong (1.28) và tương quan chéo $\rho xy(h)$, trong (1.29), được đưa ra, tương ứng, bởi hàm hiệp phương sai chéo mẫu $$\hat{\gamma}_{xy}(h)= n^{-1}.\sum _ {t = 1 } ^ {n-h} (x_{t+h}-\bar{x}).(y_{t}-\bar{y})$$
trong đó $\gamma xy(h)= yx(h)$ xác định hàm cho độ trễ âm và hàm tương quan chéo mẫu $$\hat{\rho_{xy}}(h)= \dfrac{\hat{\gamma}_{xy}(h)}{\sqrt{\hat{\gamma_{x}}(0).\hat{\gamma_{y}}(0)}}$$
\end{dn}
Hàm tương quan chéo mẫu có thể được kiểm tra bằng đồ họa như một hàm của độ trễ h để tìm kiếm các mối quan hệ hàng đầu hoặc độ trễ trong dữ liệu bằng cách sử dụng tính chất được đề cập trong ví dụ 1.22 cho lý thuyết hàm hiệp phương sai . Vì $-1\leqslant xy(h)$, tầm quan trọng thực tế của các đỉnh có thể được đánh giá bằng cách so sánh độ lớn của chúng với mức tối đa lý thuyết của các giá trị. Hơn nữa, đối với các quá trình tuyến tính độc lập $x_{t}$ và $y_{t}$ của mẫu (1.31), chúng tôi có 
\begin{dl}
\textbf{Phân phối mẫu lớn của Tương quan chéo Dưới sự độc lập}\
	
Phân phối mẫu lớn của $\rho xy(h)$ là bình thường với giá trị trung bình bằng 0 và $$\sigma_{\hat{\rho}_{xy}}=\dfrac{1}{\sqrt{n}}$$
nếu ít nhất một trong các quá trình là nhiễu trắng độc lập (xem Định lý A.8 trong Phụ lục A).
\end{dl}
\subsection{Hồi quy cổ điển trong phân tích chuỗi thời gian}
Chúng ta bắt đầu thảo luận về hồi quy tuyến tính trong chuỗi thời gian bằng cách giả sử một số chuỗi thời gian đầu ra hoặc phụ thuộc, giả sử, $x_{t}$, cho $t = 1 ,. . . , n$, đang bị ảnh hưởng bởi một tập hợp các đầu vào có thể hoặc chuỗi độc lập, giả sử, $z_{t1}, z_{t2},...z_{tn}$ nơi đầu tiên chúng tôi coi đầu vào là cố định và đã biết. Giả định này, cần thiết để áp dụng hồi quy tuyến tính thông thường, sẽ được nới lỏng sau này. Chúng tôi biểu thị mối quan hệ này thông qua mô hình hồi quy tuyến tính 
$$x_{t}=\beta_{1}z_{t1} + \beta_{2}z_{t2} +...+ \beta_{q}z_{tq} +\omega_{1}$$
trong đó $\beta_{1},\beta_{2},...,\beta_{q}$ là các hệ số hồi quy cố định chưa biết và $ {\omega_{t}} $ là một lỗi ngẫu nhiên hoặc quá trình nhiễu bao gồm các biến thông thường độc lập và phân phối (iid) với giá trị trung bình bằng 0 và phương sai $ \sigma_{\omega}^{2} $; chúng ta sẽ nới lỏng giả định iid sau. Một thiết lập tổng quát hơn để nhúng ước lượng bình phương trung bình và hồi quy tuyến tính được nêu trong Phụ lục B, trong đó chúng tôi giới thiệu các không gian Hilbert và Định lý Chiếu

Mô hình tuyến tính được mô tả bởi (2.1) ở trên có thể được viết một cách thuận tiện bằng ký hiệu tổng quát hơn bằng cách xác định các vectơ cột $z_{t}(z_{t1},z_{t2},...,z_{tq})^{'}$ và $\beta_{t}(\beta_{1},\beta_{2},...,\beta_{q})^{'}$, trong đó biểu thị chuyển vị, vì vậy (2.1) có thể được viết ở dạng thay thế	
$$x_{t}=\beta^{'} z_{t} + \omega_{t} $$
trong đó $\omega_{t} \sim idd(0,\sigma_{\omega}^{2})$ Việc xem xét ước tính vectơ hệ số chưa biết là điều tự nhiên bằng cách giảm thiểu số dư tổng bình phương

$$ RSS = \sum_{t=1}^{n} (x_{t}- \beta ^{'}z_{t})^{2} $$
đối với $\beta_{1},\beta_{2},...,\beta_{q}$. Tối thiểu hóa RSS mang lại công cụ ước lượng bình phương nhỏ nhất. Việc giảm thiểu này có thể được thực hiện bằng cách phân biệt (2.3) đối với vectơ hoặc bằng cách sử dụng các tính chất của các phép chiếu. Trong ký hiệu trên, quy trình này đưa ra các phương trình bình thường
$$(\sum_{t=1}^{n} z_{t}z_{t}^{;})\hat{\beta}= \sum_{t=1}^{n} z_{t} x_{t}$$
Đơn giản hóa hơn nữa các kết quả ký hiệu từ việc xác định ma trận 
$Z=(z_{1},z_{2},...,z_{n})^{'}$ là ma trận $n\times q$ bao gồm n mẫu của các biến đầu vào và vectơ $n \times 1$ quan sát $x=(x_{1},x_{2},...,x_{n})^{'}$ Nhận dạng này mang lại:
$$(Z^{'}Z)\hat{\beta}=Z^{'}x$$
và giải pháp
$$\hat{\beta}=(Z^{'}Z)^{-1}Z^{'}x$$
khi ma trận $ Z^{'}Z $ có thứ hạng $ q $. Tổng số bình phương còn lại tối thiểu (2.3) có dạng ma trận tương đương
\begin{align*}
RSS&=(x-Z\hat{\beta})^{'}(x-Z\hat{\beta})\\
&=x^{'}x-\hat{\beta}^{'}Z^{'}x\\
&=x^{'}x-x^{'}Z(Z^{'}Z)^{-1}Z^{'}x\\
\end{align*}
để đưa ra một số phiên bản hữu ích để tham khảo sau này. Các công cụ ước lượng bình phương nhỏ nhất thông thường là ‘’không chệch’’, tức là, $E(\hat{\beta})=\beta$ và có phương sai nhỏ nhất trong lớp các công cụ ước lượng ‘không chệch’ tuyến tính. Nếu các lỗi $ \omega_{t} $ là phân phối chuẩn (Gaussian), $ \beta $ cũng là mức tối đa ước tính khả năng cho và phân phối chuẩn với

\begin{align*}
cov(\hat{\beta})&=\sigma_{\omega}^{2}(\sum_{t=1}^{n} z_{t}z_{t}^{'})^{-1}\\
&=\sigma_{\omega}^{2}(Z^{'}Z)^{-1}\\
&=\sigma_{\omega}^{2}C\\
\end{align*}
trong đó	$$C=(Z^{'}Z)^{-1}$$
là một ký hiệu thuận tiện cho các phương trình sau này. Công cụ ước lượng không chệch cho phương sai $ \sigma_{\omega}^{2} $ là
$$s_{\omega}^{2}=\dfrac{RSS}{n-q}$$
Là tương phản với công cụ ước tính khả năng tối đa $\hat{\sigma}_{\omega}^{2}=RSS/n$ có ước số n. Theo giả định bình thường, $ s_{\omega}^{2} $ được phân phối tỷ lệ với một biến ngẫu nhiên chi bình phương với $ n - q $ bậc tự do, ký hiệu là $ \chi_{n-q}^{2} $ và độc lập với $ \hat{\beta} $. Theo đó
$$t_{n-q}=\dfrac{(\hat{\beta}_{i}-\beta_{i})}{s_{\omega}\sqrt{c_{ii}}}$$
có phân bố $ t $ với $ n − q $ độ tự do; $ c_{ii} $ biểu thị phần tử đường chéo thứ $ i $ của $ c $, như được định nghĩa trong (2.9).

Các mô hình cạnh tranh khác nhau được quan tâm để cô lập hoặc chọn tập hợp con tốt nhất của các biến độc lập. Giả sử một mô hình được đề xuất chỉ định rằng chỉ một tập hợp con $ q_{1}< q $ biến độc lập, giả sử, $z_{1t}=(z_{t1}, z_{t2},...z_{tq_{1}})^{'}$ đang ảnh hưởng đến biến phụ thuộc $ x_{t} $, do đó mô hình 
$$x_{t}=\beta_{1}^{'}z_{1t}+\omega_{t}$$
trở thành giả thuyết null, trong đó $\beta_{1}=(\beta_{1},\beta_{2},...,\beta_{q_{1}})^{'}$ là tập hợp con của các hệ số của các biến q ban đầu. Chúng ta có thể kiểm tra mô hình rút gọn (2.12) so với mô hình đầy đủ (2.2) bằng cách so sánh các tổng bình phương còn lại trong hai mô hình bằng cách sử dụng thống kê F
$$F_{q-q_{1}, n-q}=\frac{RSS_{1}-RSS}{RSS}\dfrac{n-q}{q-q_{1}}$$
có phân phối $ F $ trung tâm với $ q-q_{1} $ và $ n-q $ bậc tự do khi (2.12) là mô hình chính xác. Thống kê, sau khi áp dụng tiêu chí tỷ lệ khả năng, có sự cải thiện về số lượng tham số được thêm vào tử số so với lỗi  tổng bình phương theo mô hình đầy đủ trong mẫu số. Thông tin liên quan đến quy trình thử nghiệm thường được tóm tắt trong bảng Phân tích phương sai (ANOVA) như được nêu trong Bảng 2.1 cho trường hợp cụ thể này. Sự khác biệt trong tử số thường được gọi là tổng hồi quy của bình phương 

Theo Bảng 2.1, thông thường để viết thống kê $ F $ (2.13) là tỷ lệ của hai bình phương trung bình, thu được
$$F_{q-q_{1}, n-q}=\frac{MS_{reg}}{s_{\omega}^{2}}$$
Một trường hợp đặc biệt quan tâm là $ q_{1}=1 $ và $ z_{1t}=1 $, do đó mô hình trong (2.12) trở thành
$$ x_{t}=\beta_{1} + \omega_{t} $$
và chúng tôi có thể đo tỷ lệ biến thể chiếm bởi các biến khác bằng cách sử dụng
$$R_{xz}^{2}=\dfrac{RSS_{0}-RSS}{RSS_{0}}$$
trong đó tổng bình phương còn lại theo mô hình rút gọn
$$RSS_{0}= \sum_{t=1}^{n} (x_{t}-\bar{x})^{2}$$
trong trường hợp này chỉ là tổng độ lệch bình phương so với trung bình $\bar{x}$. Các biện pháp$ R_{xz}^{2} $ cũng là tương quan bội bình phương giữa xt và các biến $ z_{t1}, z_{t2},...z_{tq_{1}} $

Các kỹ thuật được thảo luận trong đoạn trước có thể được sử dụng để kiểm tra các mô hình khác nhau bằng cách sử dụng thử nghiệm $ F $ được đưa ra trong (2.13), (2.14) và bảng ANOVA. Các thử nghiệm này đã được sử dụng trong quá khứ theo cách từng bước, trong đó các biến được thêm hoặc xóa khi các giá trị từ $F$-test hoặc vượt quá hoặc không vượt quá một số mức định trước. Quy trình, được gọi là hồi quy nhiều bước, rất hữu ích trong việc đưa ra một tập hợp các biến hữu ích. Một cách khác là tập trung vào một quy trình lựa chọn mô hình không tiến hành tuần tự, mà chỉ đơn giản là đánh giá từng mô hình theo giá trị riêng của nó. Giả sử chúng ta xem xét một mô hình hồi quy với hệ số $ k $ và biểu thị khả năng  ước tính mức tối đa cho phương sai như	
$$\hat{\sigma}_{k}^{2}=\dfrac{RSS_{k}}{n}$$
trong đó $ RSS_{k} $ biểu thị tổng số bình phương còn lại theo mô hình với các hệ số hồi quy $ k $. Sau đó, Akaike (1969, 1973, 1974) đề nghị đo lường mức độ phù hợp của mô hình cụ thể này bằng cách cân bằng lỗi của sự phù hợp với số lượng tham số trong mô hình; chúng tôi xác định 
\begin{dn}	
	\textit{Tiêu chuẩn thông tin Akaike (AIC)} 
	$$AIC= ln (\hat{\sigma}_{k}^{2}) +\dfrac{n+ 2k}{n}$$
	trong đó $ \hat{\sigma}_{k}^{2} $ được cho bởi (2.17) và $ k $ là số lượng tham số trong mô hình.
\end{dn}
Giá trị của $ k $ mang lại AIC tối thiểu chỉ định mô hình tốt nhất. Ý tưởng đại khái là giảm thiểu $ \hat{\sigma}_{k}^{2} $ sẽ là một mục tiêu hợp lý, ngoại trừ việc nó giảm đơn điệu khi $ k $ tăng. Do đó, chúng ta nên xử lý lỗi phương sai  bằng một thuật ngữ tỷ lệ thuận với số lượng tham số. Sự lựa chọn cho thời hạn hình thức xử lý được đưa ra bởi (2.18) không phải là duy nhất và có sẵn một tài liệu đáng kể ủng hộ các điều khoản xử lý khác nhau.Sự lựa chọn cho thời hạn hình thức xử lý được đưa ra bởi (2.18) không phải là duy nhất và có sẵn một tài liệu đáng kể ủng hộ các điều khoản phạt khác nhau.. Một dạng chính xác, được đề xuất bởi Sugiura (1978) và được mở rộng bởi Hurvich và Tsai (1989), có thể dựa trên kết quả phân phối mẫu nhỏ cho mô hình hồi quy tuyến tính (chi tiết được cung cấp trong Bài toán 2.4 và 2.5). Các hình thức sửa chữa được định nghĩa là:
\begin{dn}	
	\textit{Tiêu chuẩn AIC hiệu chỉnh (AIC)} 
	$$AIC_{c}= ln (\hat{\sigma}_{k}^{2}) +\dfrac{n+ k}{n-k-2}$$
	Trong đó $ \hat{\sigma}_{k}^{2} $ được cho bởi (2.17), $ k $ là số lượng tham số trong mô hình và $ n  $là cỡ mẫu.
	
\end{dn}
Chúng tôi cũng có thể rút ra một thuật ngữ điều chỉnh dựa trên các lập luận Bayes, như trong Schwarz (1978), dẫn đến
\begin{dn}	
	\textit{Tiêu chuẩn thông tin Schwarz (SIC)} 
	$$SIC= ln (\hat{\sigma}_{k}^{2}) +\dfrac{k.ln(n)}{n}$$
	sử dụng ký hiệu tương tự như trong Định nghĩa 2.2
\end{dn}
SIC còn được gọi là Tiêu chuẩn Thông tin Bayes (BIC) (xem thêm Rissanen,1978, cho một cách tiếp cận mang lại thống kê tương tự dựa trên đối số độ dài mô tả tối thiểu). Các nghiên cứu mô phỏng khác nhau có xu hướng xác minh rằng SIC thực hiện tốt thứ tự đúng trong các mẫu lớn, trong khi AICc có xu hướng vượt trội trong các mẫu nhỏ hơn với số lượng tham số tương đối lớn (xem McQuarrie và Tsai, 1998, để so sánh chi tiết). Trong các mô hình hồi quy phù hợp, hai biện pháp đã được sử dụng trong quá khứ là bình phương R được điều chỉnh, về cơ bản là $ s_{\omega}^2 $ và Mallows $ C_{p} $, Mallows (1973), mà chúng tôi không xem xét trong bối cảnh này.
\subsection{Phân tích dữ liệu thăm dò}
Nói chung, dữ liệu chuỗi thời gian có tính dừng là cần thiết, do đó, trung bình các sản phẩm bị trễ theo thời gian, như trong phần trước, sẽ là một điều hợp lý để làm. Với dữ liệu chuỗi thời gian, chính sự phụ thuộc giữa các giá trị của chuỗi là quan trọng để đo lường; ít nhất, chúng ta phải có khả năng ước tính độ tự tương quan với độ chính xác. Sẽ rất khó để đo lường sự phụ thuộc đó nếu cấu trúc phụ thuộc không thường xuyên hoặc đang thay đổi tại mọi thời điểm.
Do đó, để đạt được bất kỳ phân tích thống kê có ý nghĩa nào về dữ liệu chuỗi thời gian, điều quan trọng là, nếu không có gì khác, hàm trung bình và hàm tự hiệp phương sai thỏa mãn các điều kiện ổn định (ít nhất là một khoảng thời gian hợp lý) được nêu trong Định nghĩa 1.7. Thông thường, đây không phải là trường hợp, và chúng tôi sẽ đề cập đến một số phương pháp trong phần này để phát huy tác dụng của tính không ổn định  để các tính ổn định của chuỗi thời gian có thể được nghiên cứu. 
Một số ví dụ của chúng tôi rõ ràng là chuỗi không ổn định. Chuỗi Johnson $ \& $ Johnson trong Hình 1.1 có nghĩa là tăng theo cấp số nhân theo thời gian và sự gia tăng cường độ của các dao động xung quanh xu hướng này gây ra những thay đổi trong hàm hiệp phương sai; phương sai của quá trình, ví dụ, rõ ràng tăng lên khi một tiến trình trong suốt chiều dài của chuỗi. Ngoài ra, chuỗi nhiệt độ toàn cầu trong Hình 1.2 chứa một số bằng chứng về xu hướng theo thời gian; Những người ủng hộ sự nóng lên toàn cầu do con người gây ra đã coi đây là bằng chứng thực nghiệm để đưa ra giả thuyết của họ rằng nhiệt độ là tăng. 
Có lẽ hình thức không dừng nhất để làm việc là mô hình xu hướng dừng trong đó quy trình có tính dừng xung quanh một xu hướng. Chúng tôi có thể viết loại mô hình này như
$$ x_{t}=\mu_{t}+y_{t} $$
Trong đó $ x_{t} $ là các quan sát, $ \mu_{t} $ biểu thị xu hướng và $ y_{t} $ là một quá trình ổn định. Rất thường xuyên, xu hướng mạnh mẽ,$ \mu_{t} $ , sẽ che khuất hành vi của quá trình dừng,$ y_{t} $ như chúng ta sẽ thấy trong nhiều ví dụ trong Chương 3. Do đó, có một số lợi thế để loại bỏ xu hướng là bước đầu tiên trong phân tích thăm dò về điều đó chuỗi thời gian. Các bước liên quan là để có được ước tính hợp lý của thành phần xu hướng, giả sử $ \hat{\mu}_{t} $ , và sau đó làm việc với phần dư
$$ \hat{y}_{t}=x_{t}-\hat{\mu}_{t} $$
Một lợi thế của sự khác biệt so với giảm dần để loại bỏ xu hướng là không có tham số nào được ước tính trong toán tử sai phân. Tuy nhiên, một nhược điểm là sai phan không mang lại ước tính về quá trình dừng $y_{t}$ như có thể thấy trong (2.28). Nếu một ước tính của $ y_{t} $ là cần thiết, thì việc giảm xu hướng có thể phù hợp hơn. Nếu mục tiêu là ép buộc dữ liệu về tính dừng, thì sai phân có thể phù hợp hơn. Sự khác biệt cũng là một công cụ khả thi nếu xu hướng được cố định, như trong ví dụ 2.3. Đó là, ví dụ, nếu $ \mu_{t}=\beta_{1}+\beta_{2}t $trong mô hình (2.25), phân biệt dữ liệu tạo ra sự ổn định (xem Bài toán 2.6):
$$	x_{t}-x_{t-1}= (\mu_{t}+y_{t})- (\mu_{t-1}+y_{t-1})= \beta_{2} + y_{t}- y_{t-1}$$
Bởi vì sai phân đóng vai trò trung tâm trong phân tích chuỗi thời gian, nó nhận được ký hiệu riêng. Sự khác biệt đầu tiên được ký hiệu là
$$\nabla x_{t}=x_{t}-x_{t-1}$$
Như chúng ta đã thấy, sai phân đầu tiên loại bỏ xu hướng tuyến tính. Một sự khác biệt thứ hai, đó là sai phân của (2.29), có thể loại bỏ xu hướng bậc hai, v.v. Để xác định sai phân cao hơn, chúng ta cần một biến thể trong ký hiệu mà chúng ta sử dụng, lần đầu tiên ở đây và thường là trong cuộc thảo luận của chúng ta về các mô hình ARIMA trong Chương 3.
\begin{dn}
	Chúng tôi định nghĩa toán tử backshift bằng
	$$Bx_{t}=x_{t-1}$$
	và mở rộng nó thành lũy thừa 	$B^{2}x_{t}=B(Bx_{t})=Bx_{t-1}=Bx_{t-2}$. Như vậy
	$$B^{k}x_{t}=x_{t-k}$$
\end{dn}
Rõ ràng là sau đó chúng tôi có thể viết lại (2.29) thành
$$\nabla x_{t}=(1-B)x_{t}$$
và chúng tôi có thể mở rộng khái niệm hơn nữa. Ví dụ, sai phân bậc hai trở thành
\begin{align*}
\nabla^{2} x_{t} &=(1-B)^{2}x_{t}=(1-2B+B^{2})x_{t}\\
&=x_{t}-2x_{t-1}+x_{t-2}\\	
\end{align*}
bởi tính tuyến tính của toán tử. Để kiểm tra, chỉ cần lấy sai phân của sai phân bậc nhất
$\nabla(\nabla x_{t})=\nabla (x_{t}-x_{t-1})- (x_{t-1}-x_{t-2})$
\begin{dn}
	Sai phân bậc d được định nghĩa là
	$$\nabla^{d}=(1-B)^{d}$$
	trong đó chúng ta có thể mở rộng toán tử $ (1-B)^{d} $ theo đại số để đánh giá các giá trị nguyên cao hơn của d. Khi $ d = 1 $, chúng ta bỏ nó từ ký hiệu.
\end{dn}
Sai phân bậc nhất (2.29) là một ví dụ về bộ lọc tuyến tính được áp dụng để loại bỏ xu hướng. Các bộ lọc khác, được hình thành bằng các giá trị trung bình gần $ x_{t} $, có thể tạo ra chuỗi điều chỉnh loại bỏ các loại dao động không mong muốn khác, như trong Chương 3. Kỹ thuật khác biệt là một thành phần quan trọng của mô hình ARIMA của Box và Jenkins (1970) (xem thêm Box et al., 1994), sẽ được thảo luận trong Chương 3
Một thay thế cho sai phân là một hoạt động ít nghiêm trọng hơn mà vẫn giả định sự ổn định của chuỗi thời gian cơ bản. Sự thay thế này, được gọi là phân biệt phân số, mở rộng khái niệm toán tử sai phân (2.32) thành các lũy thừa phân số $ −.5 <d <.5 $, vẫn xác định các quy trình dừng. Granger và Joyeux (1980) và Hosking (1981) đã giới thiệu chuỗi thời gian bộ nhớ dài, tương ứng với trường hợp khi $ 0 <d <.5 $. Mô hình này thường được sử dụng cho chuỗi thời gian môi trường phát sinh trong thủy văn.
Thông thường, hiện tượng quang sai rõ ràng có thể đóng góp hành vi không dừng cũng như phi tuyến tính trong chuỗi thời gian quan sát được. Trong trường hợp như vậy, biến đổi có thể hữu ích để cân bằng sự thay đổi theo chiều dài của một chuỗi. Một chuyển đổi đặc biệt hữu ích là
$$y_{t}=ln(x_{t})$$
có xu hướng triệt tiêu các dao động lớn hơn xảy ra trên các phần của chuỗi trong đó các giá trị cơ bản lớn hơn. Các khả năng khác là biến đổi cơ số trong họ Box$-$Cox có dạng
\begin{align*}
y_{t}=
\begin{cases} 
(x_{t}^{\lambda}-1)/\lambda&, \lambda\neq 0\\
ln(x_{t})&, \lambda=0\\
\end{cases}
\end{align*}
Phương pháp chọn cơ số $ \lambda $ có sẵn (xem Johnson và Wicéc, 1992) nhưng chúng tôi không theo đuổi chúng ở đây. Thông thường, các phép biến đổi cũng được sử dụng để cải thiện tính gần đúng với tính quy tắc hoặc để cải thiện tính tuyến tính trong việc dự đoán giá trị của chuỗi này từ chuỗi khác.
Là một công cụ thăm dò cuối cùng, chúng tôi thảo luận về việc đánh giá hành vi định kỳ trong dữ liệu chuỗi thời gian bằng cách sử dụng phân tích hồi quy và biểu đồ; tài liệu này có thể được coi là một giới thiệu về phân tích quang phổ, mà chúng ta thảo luận trong chi tiết trong Chương 4.. Trong ví dụ 1.12, chúng tôi đã thảo luận ngắn gọn về vấn đề xác định tín hiệu tuần hoàn hoặc định kỳ theo chuỗi thời gian. Một số chuỗi thời gian chúng ta đã thấy cho đến nay thể hiện hành vi định kỳ. 
\subsection{Làm mịn trong chuỗi thời gian}
Trong 1.4, chúng tôi đã đưa ra khái niệm làm mịn chuỗi thời gian và trong Ví dụ 1.9, chúng tôi đã thảo luận về việc sử dụng trung bình trượt để làm nhiễu trắng mịn. Phương pháp này rất hữu ích trong việc khám phá những đặc điểm nhất định trong một chuỗi thời gian, chẳng hạn như xu hướng dài hạn và các thành phần theo mùa. Cụ thể, nếu $ x_{t} $ đại diện cho các quan sát, sau đó
$$m_{t}= \sum_{j=-k}^{k} a_{j}x_{t-j}$$
trong đó $a_{j}=a_{-j}\geq 0$ và $\sum_{j=-k}^{k} a_{j}=1$ là trung bình trượt đối xứng của dữ liệu.
\subsection{Phân tích residual}
Mỗi quan sát trong một chuỗi thời gian có thể được dự báo bằng cách sử dụng tất cả các quan sát trước đó. Chúng tôi gọi những giá trị được trang bị này và chúng được ký hiệu là $\hat{y}_{t\mid t-1}$ có nghĩa là dự báo của yt dựa trên các quan sát $y_{1}...y_{t-1}$ Chúng tôi sử dụng chúng rất thường xuyên, đôi khi chúng tôi bỏ một phần của chỉ mục và chỉ viết $y_{t}$ thay vì $y_{t\mid t-1}$ Giá trị được trang bị luôn liên quan đến dự báo một bước.

Trên thực tế, các giá trị được trang bị thường không phải là dự báo đúng vì bất kỳ tham số nào liên quan đến phương pháp dự báo đều được ước tính bằng cách sử dụng tất cả các quan sát có sẵn trong chuỗi thời gian, bao gồm cả các quan sát trong tương lai. Ví dụ: nếu chúng ta sử dụng phương pháp trung bình, các giá trị được trang bị $$\hat{y}_{t}=\hat{c}$$
Trong đó $\hat{c}$ là giá trị trung bình được tính trên tất cả các quan sát có sẵn, bao gồm cả những lần quan sát sau $t$. Tương tự, đối với phương pháp drift, tham số drift được ước tính bằng cách sử dụng tất cả các quan sát có sẵn. Trong trường hợp này, các giá trị được trang bị được đưa ra bởi $$\hat{y}_{t}=y_{t-1}+\hat{c}$$ tại $\hat{c}=\dfrac{(y_{T}-y_{1})}{(T-1)}$ . Trong cả hai trường hợp, có một tham số được ước tính từ dữ liệu. Chiếc mũ của người Bỉ ở trên c nhắc nhở chúng ta rằng đây là một ước tính. Khi ước tính của $c$ liên quan đến các quan sát sau thời gian $t$, các giá trị được trang bị không phải là dự báo đúng. Mặt khác, các dự báo ngây thơ hoặc theo mùa không liên quan đến bất kỳ tham số nào, và vì vậy các giá trị phù hợp là dự báo đúng trong các trường hợp như vậy.

\textit{Thặng dư}

Phần còn lại của người Viking trong mô hình chuỗi thời gian là những gì còn sót lại sau khi lắp mô hình. Đối với nhiều mô hình chuỗi thời gian (nhưng không phải tất cả), phần dư bằng với chênh lệch giữa các quan sát và giá trị được trang bị tương ứng: $$e_{t}=y_{t}-\hat{y}_{t}$$
Dư lượng rất hữu ích trong việc kiểm tra xem một mô hình đã nắm bắt đầy đủ thông tin trong dữ liệu hay chưa. Một phương pháp dự báo tốt sẽ mang lại số dư với các thuộc tính sau:

1.	Phần còn lại là không tương thích. Nếu có mối tương quan giữa các phần dư, thì sẽ có thông tin còn lại trong phần dư cần được sử dụng trong dự báo tính toán.

2.	Phần dư có nghĩa là không. Nếu phần dư có giá trị trung bình khác 0, thì dự báo bị sai lệch.

Bất kỳ phương pháp dự báo nào không thỏa mãn các tính chất này đều có thể được cải thiện. Tuy nhiên, điều đó không có nghĩa là các phương pháp dự báo thỏa mãn các tính chất này không thể được cải thiện. Có thể có một số phương pháp dự báo khác nhau cho cùng một tập dữ liệu, tất cả đều đáp ứng các thuộc tính này. Kiểm tra các thuộc tính này rất quan trọng để xem liệu một phương thức có sử dụng tất cả các thông tin có sẵn hay không, nhưng đó không phải là một cách tốt để chọn phương pháp dự báo.

Nếu một trong hai tính chất này không được thỏa mãn, thì phương pháp dự báo có thể được sửa đổi để đưa ra dự báo tốt hơn. Điều chỉnh cho độ lệch là dễ dàng: nếu phần dư có nghĩa là m, thì chỉ cần thêm m vào tất cả các dự báo và vấn đề sai lệch được giải quyết. Khắc phục vấn đề tương quan khó hơn và chúng tôi sẽ không giải quyết vấn đề này cho đến Chương 9.

Ngoài các tính chất cần thiết này, nó còn hữu ích (nhưng không cần thiết) cho phần dư cũng có hai thuộc tính sau.

3. Phần dư có phương sai không đổi.

4. Phần dư được phân phối bình thường.

Hai thuộc tính này làm cho việc tính toán các khoảng dự đoán dễ dàng hơn (xem Phần 3.5 để biết ví dụ). Tuy nhiên, một phương pháp dự báo không thỏa mãn các tính chất này không nhất thiết phải được cải thiện. Đôi khi áp dụng chuyển đổi Box-Cox có thể hỗ trợ các tính chất này, nhưng nếu không, bạn thường có thể làm rất ít để đảm bảo rằng phần dư của bạn có phương sai không đổi và phân phối bình thường. Thay vào đó, một cách tiếp cận khác để có được các khoảng dự đoán là cần thiết. Một lần nữa, chúng tôi sẽ không giải quyết làm thế nào để làm điều này cho đến sau này trong cuốn sách.

Ngoài việc xem xét biểu đồ ACF, chúng tôi cũng có thể thực hiện một thử nghiệm chính thức hơn cho tự động tương quan bằng cách xem xét toàn bộ tập hợp các giá trị $r_{k}$ như một nhóm, thay vì xử lý riêng từng nhóm. Hãy nhớ lại rằng $r_{k}$ là autocorrelation cho lag $k$. Khi chúng ta nhìn vào biểu đồ ACF để xem liệu mỗi đột biến có nằm trong giới hạn yêu cầu hay không, chúng ta đang thực hiện nhiều thử nghiệm giả thuyết, mỗi thử nghiệm có xác suất dương tính nhỏ. Khi đủ các xét nghiệm này được thực hiện, có khả năng ít nhất một xét nghiệm sẽ cho kết quả dương tính giả, và vì vậy chúng tôi có thể kết luận rằng phần dư có một số tự tương quan còn lại, trong khi thực tế chúng không có. 

Để khắc phục vấn đề này, chúng tôi kiểm tra xem $h$ đầu tiên autocorrelations khác biệt đáng kể so với những gì sẽ được mong đợi từ một quá trình tiếng ồn trắng. Một thử nghiệm cho một nhóm tự động tương quan được gọi là thử nghiệm portmanteau, từ một từ tiếng Pháp mô tả một chiếc vali có chứa một số mặt hàng.
Một thử nghiệm như vậy là thử nghiệm Box-Pierce, dựa trên thống kê sau $$Q=T\sum _ {k = 1 } ^ { h } r_{k}^{2}$$
Trong đó $h$ là độ trễ tối đa đang được xem xét và $T$ là số lượng quan sát. Nếu mỗi $r_{k}$ gần bằng $0$ thì $Q$ sẽ nhỏ. Nếu một số giá trị $r_{k}$ lớn (dương hoặc âm), thì $Q$ sẽ lớn. Chúng tôi khuyên bạn nên sử dụng $h = 10$ cho dữ liệu không theo mùa và $h = 2m$ cho dữ liệu theo mùa, trong đó $m$ là khoảng thời gian theo mùa. Tuy nhiên, thử nghiệm không tốt khi $h$ lớn, vì vậy nếu các giá trị này lớn hơn $\dfrac{T}{5}$, thì sử dụng $h = \dfrac{T}{5}$

Một thử nghiệm liên quan (và chính xác hơn) là thử nghiệm Ljung-Box, dựa trên	
$$Q^{*}=T(T+2)\sum _ {k = 1 } ^ { h }(T-k)^{-1}r_{k}^{2}$$
Một lần nữa, các giá trị lớn của $Q^{*}$ gợi ý rằng sự tự tương quan không đến từ chuỗi nhiễu trắng.

Làm thế nào lớn là quá lớn? Nếu tự động tương quan xuất phát từ một chuỗi nhiễu trắng, thì cả $Q$ và $Q^{*}$ sẽ có phân phối $X^{2}$ với $(h − K)$ bậc tự do, trong đó $K$ là số lượng tham số trong mô hình. Nếu chúng được tính toán từ dữ liệu thô (thay vì phần dư từ một mô hình), thì đặt $K = 0$.

Đối với ví dụ về giá cổ phiếu của Google, mô hình navie không có tham số, vì vậy $K = 0$ trong trường hợp đó cũng vậy.
Đối với cả $Q$ và $Q^{*}$, kết quả không đáng kể (nghĩa là, giá trị $p$ tương đối lớn). Vì vậy, chúng ta có thể kết luận rằng phần dư không thể phân biệt được với một chuỗi nhiễu trắng.
Tất cả các phương pháp này để kiểm tra phần dư được đóng gói thuận tiện vào một hàm checkresiduals () sẽ tạo ra một biểu đồ thời gian, biểu đồ ACF và biểu đồ của phần dư (với phân phối bình thường để so sánh) và thực hiện kiểm tra Ljung-Box với mức độ tự do chính xác.
\\

Dự đoán chuỗi thời gian là việc sử dụng mô hình để dự đoán các sự kiện thời gian dựa vào các sự kiện đã biết trong quá khứ để từ đó dự đoán các điểm dữ liệu trước khi nó xảy ra (hoặc được đo). Trong thực tế, dự báo chính xác là một nhiệm vụ quan trọng nhưng thường là khó khăn đối với các nhà hoạch định chính sách trong nhiều lĩnh vực. Mặc dù có rất nhiều mô hình được ứng dụng trong việc dự báo nhưng mỗi mô hình đều có ưu điểm và hạn chế riêng. Trong đó, mô hình trung bình chuyển động kết hợp tự hồi quy (ARIMA) là một trong những mô hình tuyến tính phổ biến nhất trong dự báo chuỗi thời gian đã được áp dụng rộng rãi để xây dựng các mô hình lai chính xác hơn trong thập kỷ qua. Theo Khashei và Bijari (2011). Mô hình này cũng được đánh giá là phù hợp đối với những quan hệ tuyến tính giữa dữ liệu hiện tại và dữ liệu quá khứ. Trong phần tiếp theo, chúng tôi sẽ giới thiệu lý thuyết xây dựng mô hình ARIMA.
\section{Mô hình ARIMA và dự báo}
\subsection{Giới thiệu mô hình ARIMA}

Mô hình ARIMA (Autoregressive Integrated Moving Average – Tự hồi qui tích hợp Trung bình trượt) là một lớp mô hình tuyến tính có khả năng biểu diễn cả chuỗi thời gian tĩnh lẫn không tĩnh. Mô hình ARIMA dựa vào các mẫu tự tương quan trong bản thân của chuỗi thời gian để sinh ra dự đoán. Hệ thống các phương pháp dùng để xác định, kiểm tra và cải tiến mô hình ARIMA có sự đóng góp rất lớn của hai nhà thống kê, G.E.P.Box và G.M.Jenkins (1976). Do đó việc mô hình và dự đoán dựa trên mô hình ARIMA còn được gọi là phương pháp luận Box-Jenkins. 
\subsection{Mô hình ARMA}
Mô hình hồi quy cổ điển ở Chương 2 được phát triển cho trường hợp tĩnh, cụ thể là, chúng tôi chỉ cho phép biến phụ thuộc được tính bằng các giá trị hiện tại của các biến độc lập. Trong trường hợp chuỗi thời gian, cho phép biến phụ thuộc được tính bằng các giá trị trong quá khứ của các biến độc lập và có thể bằng các giá trị trong quá khứ của chính nó. Nếu hiện tại có thể được mô hình hóa hợp lý theo các giá trị trong quá khứ của các đầu vào độc lập, chúng ta có triển vọng hấp dẫn rằng dự báo sẽ có thể.

Giới thiệu về các mô hình tự động

Các mô hình tự động dựa trên ý tưởng rằng giá trị hiện tại của chuỗi, $x_{t}$, có thể được giải thích là hàm của các giá trị $p$ trong quá khứ, $x_{t-1}, x_{t-2}, ..., x_{t-p}$, trong đó $p$ xác định số lượng bước vào quá khứ cần thiết để dự báo giá trị hiện tại. Như một trường hợp điển hình, nhớ lại Ví dụ 1.10 trong đó dữ liệu được tạo bằng mô hình
$$x_{t}= x_{t-1} - .90x_{t-2} +w_{t}$$
Trong đó $w_{t} $ là nhiễu Gaussian trắng với $\delta_{w}^{2}=1$. Hiện tại chúng ta đã giả sử giá trị hiện tại là một hàm tuyến tính cụ thể của các giá trị trong quá khứ. Sự đều đặn vẫn tồn tại trong Hình 1.9 đưa ra một dấu hiệu cho thấy dự báo cho một mô hình như vậy có thể là một khả năng khác biệt, thông qua một số phiên bản như
$$x_{n+1}^{n} =  x_{n} - .90x_{n-1}$$
trong đó đại lượng ở phía bên trái biểu thị dự báo ở giai đoạn tiếp theo $n + 1$ dựa trên dữ liệu được quan sát, $x_{1}, x_{2}, ..., x_{n}$. Chúng tôi sẽ làm cho khái niệm này chính xác hơn trong cuộc thảo luận về dự báo của chúng tôi (§3,5).

Mức độ có thể dự đoán chuỗi dữ liệu thực từ các giá trị trong quá khứ của chính nó có thể được đánh giá bằng cách xem xét hàm tự tương quan và ma trận phân tán bị trễ được thảo luận trong Chương 2. Ví dụ, ma trận phân tán bị trễ cho chỉ số dao động miền Nam (SOI), như trong Hình 2.7, đưa ra một dấu hiệu riêng biệt cho thấy độ trễ 1 và 2, ví dụ, được liên kết tuyến tính với giá trị hiện tại. ACF được hiển thị trong Hình 1.14 cho thấy các giá trị dương tương đối lớn ở độ trễ 1, 2, 12, 24 và 36 và các giá trị âm lớn ở 18, 30 và 42. Chúng tôi cũng lưu ý mối quan hệ có thể có giữa chuỗi SOI và Tuyển dụng được chỉ ra trong ma trận phân tán trong hình 2.8. Chúng tôi sẽ chỉ ra trong các phần sau về chức năng truyền và mô hình AR vector làm thế nào để xử lý sự phụ thuộc vào các giá trị được thực hiện bởi các chuỗi khác. Các cuộc thảo luận trước thúc đẩy các mục tiêu sau đây.
\begin{dn}
	Một mô hình tự phát theo thứ tự p, viết tắt AR (p), có dạng
	$$x_{t} = \phi_{1}x_{t-1} + \phi_{2}x_{t-2} + ...+ \phi_{p}x_{t-p}+ w_{t}$$
	trong đó $x_{t}$ đứng yên,$ \delta_{1}, \delta_{2}, ..., \delta_{p}$ là các hằng số $(\delta_{p} \neq 0)$. Trừ khi có quy định khác, chúng tôi giả sử rằng $w_{t}$ là một chuỗi nhiễu trắng Gaussian có nghĩa là 0 và phương sai $\delta_{w}^{2}$. Giá trị trung bình của $x_{t}$ trong (3.1) bằng không. Nếu giá trị trung bình, $\mu$, của $x_{t}$ không bằng 0, thay thế $x_{t}$ bằng $x_{t} − \mu$, trong (3.1), tức là,
	$$x_{t} − \mu= \phi_{1}(x_{t-1} - \mu) + \phi_{2}(x_{t-2}-\mu) + ...+\phi_{p}(x_{t-p}- \mu) +w_{t},$$
	hoặc
	$$x_{t}= \alpha + \phi_{1}x_{t-1} + \phi_{2}x_{t-2}+...+ \phi_{p}x_{t-p}+ w_{t}$$ 
	với $\alpha = \mu(1-\phi_{1}-...-\phi_{p})$
	Chúng tôi lưu ý rằng (3.2) tương tự như mô hình hồi quy của §2.2, và do đó thuật ngữ hồi quy tự động (hoặc tự). Tuy nhiên, một số văn hóa kỹ thuật phát triển từ việc áp dụng mô hình đó bởi vì các biến hồi quy, $x_{t-1}, ..., x_{t-p}$, là các thành phần ngẫu nhiên, trong khi  $z_{t}$ được giả sử là đã sửa. Một hình thức hữu ích theo sau bằng cách sử dụng toán tử dịch chuyển ngược (2.30) để viết mô hình AR(p), (3.1), như
	$$(1-\phi_{1}B - \phi_{2}B^{2}- ...- \phi_{p}B^{p})x_{t}= w_{t}$$
	hoặc thậm chí chính xác hơn như 
	$$\phi(B)x_{t}= w_{t}$$
	Các tính chất của $\phi(B)$ rất quan trọng trong việc giải (3.4) cho $x_{t}$. Điều này dẫn đến định nghĩa sau.
\end{dn}
\begin{dn}
	Toán tử tự động được xác định là
	$$\phi(B) = 1-\phi_{1}B - \phi_{2}B^{2}- ...- \phi_{p}B^{p}$$
	Chúng tôi bắt đầu điều tra các mô hình AR bằng cách xem xét mô hình thứ tự đầu tiên, AR (1), được đưa ra bởi $x_{t} = \phi x{t-1} + w_{t}$. Lặp đi lặp lại k lần, chúng ta nhận được
	\begin{align*}
	x_{t}=\phi x_{t-1} +w_{t} &= \phi(\phi x_{t-2} +w_{t-1}) +w_{t}\\&= \phi^{2}x_{t-2} + \phi w_{t-1} +w_{t}\\&= \phi^{k}x_{t-k} + \sum_{j=0}^{k-1}\phi^{j}w_{t-j}.
	\end{align*}
	Phương pháp này gợi ý rằng, bằng cách tiếp tục lặp lại các phường và cung cấp rằng $| \phi | <1$ và $x_{t}$ là văn phòng phẩm, chúng ta có thể biểu diễn mô hình AR (1) dưới dạng một quy trình tuyến tính được đưa ra bởi 1
	$$x_{t}= \sum_{j=0}^{\infty} \phi^{j}w_{t-j}$$
	Quá trình AR (1) được xác định bởi (3.6) là ổn định với giá trị trung bình
	$$E(x_{t})= \sum_{j=0}^{\infty}\phi^{j} E(w_{t-j})=0$$
	và chức năng tự động
	\begin{align*}
	\gamma(h)= cov(x_{t+h},x_{t}) &=E[(\sum_{j=o}^{\infty}\phi^{j}w_{t+h-j})(\sum_{k=0}^{\infty}\phi^{k}w_{t-k})]\\&= \delta_{w}^{2} \sum_{j=0}^{\infty} \phi^{j}\phi^{j+h}\\& = \delta_{w}^{2}\phi^{h} \sum_{j=0}^{\infty}\phi^{2j}= \dfrac{\delta_{w}^{2}\phi^{h}}{1- \phi^{2}}
	\end{align*}
	Hãy nhớ lại rằng $\gamma(h) = \gamma (-h)$, vì vậy chúng ta sẽ chỉ thể hiện chức năng tự động điều khiển cho $h \geq 0$. Từ (3.7), ACF của AR (1) là
	$$\rho(h)= \dfrac{\gamma(h)}{\gamma(0)}= \gamma(h), h\geq 0$$
	và $\rho(h)$ thỏa mãn
	$$\rho(h)= \phi \rho(h-1), h=1,2,..$$
	Chúng ta sẽ thảo luận về ACF của một mô hình AR (p) chung trong §3.4.
	
	Kỹ thuật lặp ngược để có ý tưởng về giải pháp ổn định của các mô hình AR hoạt động tốt khi $p = 1$, nhưng không cho các đơn đặt hàng lớn hơn. Một kỹ thuật chung là các hệ thống phù hợp. Hãy xem xét mô hình AR (1) ở dạng toán tử 
	$$\phi(B)x_{t}= w_{t}$$
	trong đó $\phi(B) = 1- \phi(B)$ và $|\phi| <1$. Ngoài ra, hãy viết mô hình trong phương trình (3.6) bằng cách sử dụng dạng toán tử như 
	$$x_{t}= \sum_{j=0}^{\infty}\psi_{j}w_{t-j} = \psi(B)w_{t}$$
	trong đó $\psi(B)= \sum_{j=0}^{\infty}\psi_{j}B^{j}$ và $\psi_{j} = \phi^{j}$. Giả sử chúng ta không biết rằng $\psi_{j} = \phi^{j}$ . Chúng ta có thể thay thế $\psi(B)w_{t}$ từ (3.12) cho $x_{t}$ trong (3.11) để thu được 
	$$\phi(B)\psi(B)w_{t} = w_{t}$$
	Các hệ số của B ở phía bên trái của (3.13) phải bằng với các hệ số ở phía bên phải của (3.13), có nghĩa là 
	$$(1- \phi B)(1-\psi_{1}B +\psi_{2}B^{2}+...+\psi_{j}B^{j}+...)=1$$
	Sắp xếp lại các hệ thống trong (3.14),
	$$1- (\psi_{1} -\phi)B + (\psi_{2}-\psi_{1}\phi)B^{2}+...+ (\psi_{j}-\psi_{j-1}\phi)B^{j})+...=1$$
	chúng ta thấy rằng với mỗi $j = 1, 2, ...,$ hệ số của $B^{j}$ ở bên trái phải bằng 0 vì nó bằng 0 ở bên phải. Hệ số của B ở bên trái là $(\psi_{1}-\phi)$ và đánh giá trị này bằng 0,$\psi_{1} −\phi = 0$, dẫn đến $\psi_{1} = \phi$. Tiếp tục, hệ số của $B^{2}$ là $(\psi_{2}-\psi{1}\phi)$, do đó $\psi_{2}= \phi^{2}$. Nói chung,
	$$\psi_{j}= \psi{j-1}\phi$$
	với $\psi_{0} = 1$, dẫn đến giải pháp chung $\psi_{j} = \phi^{j}$.
	Một cách khác để suy nghĩ về các hoạt động chúng ta vừa thực hiện là xem xét mô hình AR (1) ở dạng toán tử,$\phi(B)x_{t} = w_{t}$. Bây giờ nhân cả hai bên với $\phi^{-1}(B)$ (giả sử toán tử nghịch đảo tồn tại) để có được 
	$$\phi^{-1}(B)\phi(B)x_{t}= \phi^{-1}(B)w_{t}$$
	hoặc
	$$x_{t}= \phi^{-1}(B)w_{t}$$
	Ta biết
	$$\phi^{-1}(B)= 1 +\phi B+ \phi^{2}B^{2}+ ...+ \phi^{j}B^{j}+...$$
	nghĩa là, $\phi^{-1}(B)$ là $\psi(B)$ trong (3.12). Vì vậy, chúng tôi nhận thấy rằng làm việc với các toán tử cũng giống như làm việc với đa thức. Nghĩa là xem xét đa thức $\phi(z) = 1-\phi z$, trong đó là số phức và $|\phi|<1$. Sau đó,
	$$\phi^{-1}(z)= \dfrac{1}{(1-\phi z)}= 1+ \phi z+ \phi^{2} z^{2}+...+ \phi^{j} z^{j}+..., |z|\leq1$$
	và các hệ số của $B^{j}$ trong $\phi^{-1}(B)$ giống như các hệ số của $z^{j}$ trong $\phi^{-1}(z)$. Nói cách khác, chúng ta có thể coi toán tử dịch chuyển ngược, B, là một số phức, z. Những kết quả này sẽ được khái quát trong cuộc thảo luận của chúng tôi về các mô hình ARMA. Chúng ta sẽ tìm ra các đa thức tương ứng với các toán tử hữu ích trong việc khám phá các tính chất chung của các mô hình ARMA.
\end{dn}
Giới thiệu về mô hình di chuyển trung bình

Thay thế cho biểu diễn tự phát trong đó xt ở phía bên trái của phương trình được giả sử được kết hợp tuyến tính, mô hình trung bình di chuyển của thứ tự q, viết tắt là MA (q), giả sử nhiễu trắng wt ở bên phải mặt bên của phương trình định tuyến được kết hợp tuyến tính để tạo thành dữ liệu quan sát được.
\begin{dn}
	Mô hình trung bình di động của mô hình q, hoặc MA (q), được định nghĩa là 
	$$x_{t}= w_{t}+\theta_{1}w_{t-1}+ \theta_{2}w_{t-2}+...+\theta_{q}w_{t-q}$$
	trong đó có q độ trễ trong trung bình di động và $\theta_{1}, \theta_{2}, ..., \theta_{q} (\theta_{q} \neq 0)$ là các tham số. Nhiễu $w_{t}$ được giả sử là nhiễu trắng Gaussian.
	Hệ thống này giống như trung bình di chuyển được xác định là quá trình tuyến tính (3.12), trong đó $\psi_{0} = 1, \psi_{1} = \theta_{j}$, với $j = 1, ..., q$ và $ \psi_{j} = 0$ cho các giá trị khác. Chúng tôi cũng có thể viết quy trình MA(q) ở dạng tương đương
	$$x_{t}= \theta(B)w_{t}$$
	sử dụng định nghĩa sau.
\end{dn}
\begin{dn}
	Toán tử trung bình di chuyển là 
	$$\theta(B)= 1+ \theta_{1}B+\theta_{2}B^{2}+...+ \theta_{q}B^{q}$$
	Không giống như quá trình tự phát, quá trình trung bình di chuyển là ổn định cho bất kỳ giá trị nào của các tham số $\theta_{1}, ..., \theta_{q}$; chi tiết về kết quả này được cung cấp trong §3.4.
	
	Như trong trường hợp AR, đa thức, $\theta(z)$, tương ứng với các toán tử trung bình di chuyển, $\theta(B)$, sẽ hữu ích trong việc khám phá các tính chất chung của các quá trình MA. Ví dụ, theo các bước của phương trình (3.11) - (3.14), chúng ta có thể viết mô hình MA (1) là $x_{t} = \theta(B) w_{t}$, trong đó $\theta(B) = 1 + \theta B$. Nếu $| \theta | <1$, sau đó chúng ta có thể viết mô hình là $\pi (B)x_{t} = w_{t}$, trong đó $\pi(B) = \theta^{-1}(B)$. Để cho 
	$$\theta(z) = 1+\theta z, |z|\leq1, \text{khi đó}  \pi(z)= \theta^{-1} = \dfrac{1}{(1-\theta z)}= \sum_{j=0}^{\infty}(-\theta)^{j}z^{j}$$
	và $\pi(B)= \sum_{j=0}^{\infty}(-\theta)^{j}z^{j}$
\end{dn}
Mô hình trung bình di chuyển tự động

Bây giờ chúng tôi tiến hành phát triển chung về trung bình di chuyển tự động, trung bình di chuyển và trung bình di chuyển tự phát hỗn hợp (ARMA), các mô hình cho chuỗi thời gian đứng yên.
\begin{dn}
	Một chuỗi thời gian $ \{x_{t}, t=0,\pm1,\pm2,...\}$ là ARMA (p, q) nếu nó đứng yên và $ x_{t}= \varphi_{1}x_{t-1}+...\varphi_{p}x_{t-p} + w_{t} + \theta_{1}w_{t-1}+...+ \theta_{q}w_{t-q}$ với $\phi_{p} \neq 0, \theta \neq $0, và $\delta_{w}^{2}> 0$. Các tham số p và q được gọi là các lệnh trung bình tự động và trung bình di chuyển tương ứng. Nếu $x_{t}$ có một giá trị trung bình không khác nhau, chúng ta đặt $\alpha = \mu(1 − \phi_{1} -··· −\phi_{p})$ và viết mô hình là
	$$x_{t}= \alpha + \phi_{1}x_{t-1}+...+\phi_{p}x_{t-p}+w_{t}+\theta_{1}w_{t-1}+...+\theta_{q}w_{t-q}$$
	Trừ khi có quy định khác, $\{w_{t}; t = 0, \pm 1, \pm 2, ...\}$ là tiếng nhiễu trắng Gaussian.
	
	Như đã lưu ý trước đây, khi $q = 0$, mô hình được gọi là mô hình tự phát theo thứ tự p, AR(p) và khi $p = 0$, mô hình được gọi là mô hình trung bình di chuyển của đơn hàng q, MA (q). Để hỗ trợ điều tra các mô hình ARMA, sẽ rất hữu ích khi viết chúng bằng toán tử AR, (3.5) và toán tử MA, (3.17). Cụ thể, mô hình ARMA (p, q) trong (3.18) sau đó có thể được viết dưới dạng súc tích như
	$$\phi(B)x_{t}= \theta(B)w_{t}$$
	Trước khi chúng tôi thảo luận về các điều kiện theo đó (3.18) là nguyên nhân và không thể đảo ngược, chúng tôi chỉ ra một vấn đề tiềm ẩn với mô hình ARMA.
\end{dn}
\begin{dn}
	Các đa thức AR và MA được định nghĩa là 
	$$\phi(z)= 1 - \phi_{1}z - ... - \phi_{p}z^{p}, \phi_{p}\neq 0$$
	và
	$$\theta(z)= 1+ \theta_{1}z + ....+\theta_{q}z^{q},\theta_{q}\neq 0$$
	tương ứng, trong đó z là một số phức.
	
	Để giải quyết vấn đề đầu tiên, từ đó chúng ta sẽ đề cập đến một mô hình ARMA (p, q) để có nghĩa là nó ở dạng đơn giản nhất. Nghĩa là, ngoài định nghĩa ban đầu được đưa ra trong phương trình (3.18), chúng ta cũng sẽ yêu cầu (z) và (z) không có các yếu tố chung. Vì vậy, quá trình, $x_{t} = .5x_{t-1} - .5w_{t-1} + w_{t}$, được thảo luận trong ví dụ 3.5 không được gọi là quá trình ARMA (1,1) vì, ở dạng rút gọn, $x_{t}$ là nhiễu trắng.
	
	Để giải quyết vấn đề của các mô hình phụ thuộc trong tương lai, chúng tôi chính thức giới thiệu khái niệm nhân quả.
\end{dn}
\begin{dn}
	Một mô hình ARMA (p, q), $\phi(B)x_{t} = \theta(B)w_{t}$, được gọi là nhân quả, nếu chuỗi thời gian $\{x_{t}; t = 0, \pm 1, \pm 2, ...\}$ có thể được viết dưới dạng quy trình tuyến tính một phía:
	$$x_{t}= \sum_{j=0}^{\infty}\psi_{j}w_{t-j}= \psi(B)w_{t}$$
	trong đó $\psi(B)= \sum_{j=0}^{\infty}\psi_{j}B^{j}, \text{và} \sum_{j=0}^{\infty}|\psi_{j}|< \infty, \psi_{0}=1$
	Trong ví dụ 3.2, quá trình AR (1), $x_{t} = x_{t-1} + w_{t}$, chỉ là nguyên nhân khi $| \phi | <1$. Tương đương, quá trình chỉ là nguyên nhân khi gốc của $\phi(z) = 1- \phi (z)$ lớn hơn một trong giá trị tuyệt đối. Nghĩa là, gốc, giả sử, $z_{0}$, của $\phi(z)$ là $z_{0} = \dfrac{1}{z}$ (vì $(z_{0}) = 0)$ và $|z_{0}| > 1$ vì $|\phi| <1$. Nói chung, chúng tôi có các tính chất sau 
\end{dn}
\begin{tc}
	Nhân quả của quá trình ARMA (p, q), Mô hình ARMA (p, q) là nhân quả khi và chỉ khi $\phi(z) \neq 0$ cho $| z | \leq1$. Các hệ số của quy trình tuyến tính được cho trong (3.24) có thể được xác định bằng cách giải
	$$\psi(z)= \sum_{j=0}^{\infty}\psi_{j}z^{j}= \dfrac{\theta(z)}{\phi(z)}, |z|\leq1$$
	Một cách khác để diễn đạt tính chất P3.1 là quy trình ARMA chỉ là nguyên nhân khi các gốc của $\phi(z)$ nằm ngoài vòng tròn đơn vị; nghĩa là, $\phi(z) = 0$ chỉ khi $| z | > 1$. Cuối cùng, để giải quyết vấn đề về tính duy nhất được thảo luận trong Ví dụ 3.4, chúng tôi chọn mô hình cho phép đại diện tự động vượt trội.
\end{tc}
\begin{dn}
	Một mô hình $ARMA (p, q)$, $\phi(B)x_{t} = \theta(B)w_{t}$, được cho là không thể đảo ngược, nếu chuỗi thời gian $\{x_{t}; t = 0, \pm 1, \pm2, ...\}$ có thể được viết là 
	$$\pi(B)x_{t}= \sum_{j=0}^{\infty}\pi_{j}x_{t-j} = w_{t}$$
	với $\pi(B)= \sum_{j=0}^{\infty}\pi_{j}B^{j}, \text{và} \sum_{j=0}^{\infty}|\pi_{j}| < \infty, \pi_{0}=1$ 
	Tương tự như tính chất P3.1, chúng ta có tính chất sau 
\end{dn}
\begin{tc}
	Tính không khả dụng của quy trình $ARMA (p, q)$, Mô hình ARMA (p, q) không thể đảo ngược khi và chỉ khi $\theta(z) \neq0$ với $| z | \leq1$.Có thể xác định hệ số $\pi_{j}$ của $\pi(B)$ trong (3.25) bằng cách giải 
	$$\pi(z)= \sum_{j=0}^{\infty}\pi_{j}z^{j} = \dfrac{\phi(z)}{\theta(z)}, |z|\leq1$$
	Một cách khác để diễn đạt tính chất P3.2 là quy trình ARMA chỉ khả nghịch khi gốc của $\theta(z)$ nằm ngoài vòng tròn đơn vị; nghĩa là, $\theta(z) = 0$ chỉ khi $| z | > 1$. Bằng chứng về tài sản P3.1 được nêu trong Phụ lục B (bằng chứng về tài sản P3.2 là tương tự và do đó, không được cung cấp).
\end{tc}

\subsection{Phương trình sai phân}
	Nghiên cứu về hành vi của các quá trình ARMA và ACF của chúng được tăng cường đáng kể bởi kiến thức cơ bản về phương trình sai khác, đơn giản vì chúng là phương trình sai khác. Chủ đề này cũng hữu ích trong nghiên cứu các mô hình miền thời gian và các quy trình ngẫu nhiên nói chung. Chúng tôi sẽ đưa ra một tài khoản ngắn gọn và heuristic về chủ đề cùng với một số ví dụ về tính hữu ích của lý thuyết.Để biết chi tiết, người đọc được tham khảo Mickens (1987).

Giả sử chúng ta có một chuỗi các số $u_{0},u_{1},u_{2}... $ sao cho
$$u_{n} - \alpha  u_{n+1} =0  ,      \alpha \neq 0      , n=1,2,... $$
Ví dụ, nhớ lại (3.9) trong đó chúng tôi đã chỉ ra rằng ACF của quy trình AR (1) là một chuỗi, $\rho(h)$ , thỏa mãn
$$\rho(h)-\phi\rho(h-1)= 0, h=1,2,...$$
Phương trình (3.28) thể hiện phương trình sai phân đồng nhất của bậc 1. Để giải phương trình, chúng ta viết
\begin{align*}
u_{1}&= \alpha u_{0}\\
u_{2}&=\alpha u_{1}= \alpha^{2} u_{0}\\
& \colon \\
u_{n}&=\alpha u_{n-1} =\alpha^{n-1} u_{0}\\	
\end{align*}
Với một điều kiện ban đầu $u_{0}=c$  , chúng ta có thể giải (3.28), cụ thể là $u_{n}=a^{n}c$

Trong ký hiệu toán tử, (3.28) có thể được viết là $(1-\alpha B) u_{n}=0$. Đa thức liên kết với (3.28) là $\alpha (z) =1-\alpha z$, và gốc, giả sử, $z_{0}$, của đa thức này là $z_{0}= 1/a$; đó là $\alpha (z_{0}) =0$. Chúng ta biết lời giải cho (3.28), với điều kiện ban đầu $u_{0}=c$, là
$$u_{n}=a^{n}c=(z_{0}^{-1})^{n}c$$
Nghĩa là, giải pháp cho phương trình sai phân (3.28) chỉ phụ thuộc vào điều kiện ban đầu và nghịch đảo của gốc với đa thức liên quan $\alpha(z)$.

Bây giờ giả sử rằng chuỗi thỏa mãn
$$u_{n}-\alpha_{1}u_{n-1}-\alpha_{2}u_{n-2}=0, \alpha_{2}\neq 0 , n=2,3,...$$
Phương trình này là phương trình sai phân đồng nhất của bậc 2. Đa thức tương ứng là:
$$\alpha(z)=1-\alpha_{1}z-\alpha_{2}z^{2},$$
trong đó có hai gốc, nói, $z_{1}$ và $z_{2}$; nghĩa là, $\alpha(z_{1})=\alpha(z_{2})=0$. Chúng tôi sẽ xem xét hai trường hợp. Đầu tiên giả sử $z_{1}\neq z_{2}$. Vậy thì giải pháp chung cho (3.29) là
$$u_{n}=c_{1}. z_{1}^{-n} + c_{2}. z_{2}^{-n}$$
trong đó $c_{1}$ và $c_{2}$ phụ thuộc vào các điều kiện ban đầu. Khiếu nại này có thể được xác minh bằng cách thay thế trực tiếp (3.30) thành (3.29):
\begin{align*}
c_{1}. z_{1}^{-n}  + c_{2}. z_{2}^{-n} &- \alpha_{1} (	c_{1}. z_{1}^{-(n-1)}+ 	c_{2}. z_{2}^{-(n-1)}) - \alpha_{2} (	c_{1}. z_{1}^{-(n-2)}+ 	c_{2}. z_{2}^{-(n-2)})\\
&= c_{1}. z_{1}^{-n}. (1-\alpha_{1}z_{1}-\alpha_{2}. z_{1}^{2}) +  c_{2}. z_{2}^{-n}. (1-\alpha_{1}z_{2}-\alpha_{2}. z_{2}^{2})\\
&=c_{1}. z_{1}^{-n}\alpha(z_{1}) + c_{2}. z_{2}^{-n}\alpha(z_{2})\\
&=0.
\end{align*}
Cho hai điều kiện ban đầu $u_{0}$ và $u_{1}$, chúng ta có thể giải cho $c_{1}$ và $c_{2}$:
\begin{align*}
u_{0}&= c_{1}+ c_{2}\\
u_{1}&=c_{1}. z_{1}^{-1} + c_{2}. z_{2}^{-1}\\
\end{align*}
trong đó $z_{1}$và $z_{2}$ có thể được giải theo các giá trị của $\alpha_{1} $và $\alpha_{2} $ bằng cách sử dụng công thức bậc hai chẳng hạn.

Khi các gốc bằng nhau, $z_{1}=z_{2} (=z_{0})$, giải pháp chung cho (3.29) là
$$u_{n}= z_{0}^{-n} (c_{1 +c_{2}n})$$
Khiếu nại này cũng có thể được xác minh bằng cách thay thế trực tiếp (3.31) thành (3.29):
\begin{align*}
z_{0}^{-n} (c_{1 +c_{2}n})&- \alpha_{1}(z_{0}^{-(n-1)} [c_{1 + c_{2} (n-1)}]) - \alpha_{2}(z_{0}^{-(n-2)} [c_{1 + c_{2} (n-2)}])\\
&=z_{0}^{-n} (c_{1 +c_{2}n})(1-\alpha_{1}z_{0}-\alpha_{2}. z_{0}^{2}) + c_{2} z_{0}^{-n+1} (\alpha_{1}+2\alpha_{2}z_{0})\\
&=c_{2} z_{0}^{-n+1} (\alpha_{1}+2\alpha_{2}z_{0})\\
\end{align*}
Để chỉ ra rằng $(\alpha_{1}+2\alpha_{2}z_{0})=0$, ta viết $ 1-\alpha_{1}z-\alpha_{2}z^{2}=(1-z_{0}^{-1}z)^{2}$ và lấy đạo hàm tương ứng với $z$ ở cả hai phía của phương trình để thu được $ (\alpha_{1}+2\alpha_{2}z)=2z_{0}^{-1} (1-z_{0}^{-1}z)$. Do đó, $(\alpha_{1}+2\alpha_{2}z_{0})=2z_{0}^{-1} (1-z_{0}^{-1}z)=0$ như đã được hiển thị. Cuối cùng, với hai điều kiện ban đầu, $u_{0}$ và $u_{1}$, chúng ta có thể giải quyết cho $c_{1}$ và $c_{2}$:
\begin{align*}
u_{0}&= c_{1}\\
u_{1}&=(c_{1}+ c_{2}). z_{0}^{-1}\\
\end{align*}
Để tóm tắt những kết quả này, trong trường hợp gốc khác biệt, giải pháp cho phương trình sai phân đồng nhất của bậc hai 
\begin{align*}
u_{n}&= z_{1}^{-n} .( \text{một đa thức trong n có }  m_{1}-1) \\
& + z_{2}^{-n} .( \text{một đa thức trong n có }  m_{2}-1) \\
\end{align*}
Trong đó $m_{1}$ là bội số của gốc $z_{1}$ và $m_{2}$ là bội số của gốc $z_{2}$. Trong ví dụ này, tất nhiên, $m_{1}=m_{2}=1$, và chúng tôi đã gọi các đa thức của độ 0 $c_{1}$ và $c_{2}$ tương ứng. Trong trường hợp gốc lặp đi lặp lại, giải pháp là
$$u_{n}= z_{0}^{-n} .( \text{một đa thức trong n có }  m_{0}-1)$$
Trong đó $m_{0}$là bội số của gốc $z_{0}$; đó là, $m_{0}=2$. Trong trường hợp này, chúng tôi đã viết đa thức bậc một là $c_{1}+c_{2}n$.Trong cả hai trường hợp, chúng tôi đã giải quyết cho $c_{1}$ và $c_{2}$ với hai điều kiện ban đầu là $u_{1}$ và $u_{2}$.	
\subsection{Hàm tự tương quan và hàm tự tương quan riêng}
Chúng tôi bắt đầu bằng cách hiển thị ACF của một quá trình $MA(q)$, $x_{t}=\theta(B)w_{t}$, trong đó $\theta(B)=1+\theta_{1}B+...+\theta_{q}B^{q}$. Bởi vì $x_{t}$ là sự kết hợp tuyến tính hữu hạn của các thuật ngữ nhiễu trắng, quá trình này đứng yên với giá trị trung bình
$$E(x_{t})= \displaystyle\sum_{j=1}^q \theta_{j}E(w_{t-j})=0,$$ 
trong đó chúng tôi đã viết $\theta_{0}=1$ và với chức năng tự động điều khiển
\begin{align*}
	\gamma(h)= cov (x_{t+h},x_{t}) & = E\Bigg[\bigg(\displaystyle\sum_{j=0}^{q} \theta_{j}w_{t+h-j}\bigg)\bigg(\displaystyle\sum_{k=0}^{q} \theta_{k}w_{t-k}\bigg)\Bigg]\\	
	&=\begin{cases} 
	\sigma_w^{2}\displaystyle\sum_{j=0}^{q-h}\theta_{j}\theta_{j+h}&, 0\leq h\leq q \\
    0&, h>q. \\
	\end{cases}
\end{align*}
Hãy nhớ lại rằng $\gamma(h)=\gamma(-h)$, vì vậy, chúng tôi sẽ chỉ hiển thị các giá trị cho $h\geq 0$. Việc cắt $\gamma(h)$ sau độ trễ $q$ là kí hiệu của mô hình $MA(q)$. Chia  $(3.38)$ cho 0 mang lại ACF của một $MA(q)$:
\begin{align*}
\rho(h) =
\begin{cases} 
\dfrac{\displaystyle\sum_{j=0}^{q-h}\theta(j)\theta(j+h)}{1+\theta_1^{2}+...+\theta_q^{2}}&, 1 \leq h \leq q\\ 
0&, h > q.\\
\end{cases}
\end{align*}
Đối với mô hình $ARMA(p,q)$ nhân quả, $\phi(B)x_{t}=\theta(B)w_{t}$, trong đó các số $\phi(z)$ nằm ngoài vòng tròn đơn vị, hãy viết
$$x_{t}=\displaystyle\sum_{j=0}^{\infty}\psi_{j}w_{t-j}.$$
Ngay sau $E(x_{t}=0)$. Ngoài ra , hàm hiệp phương thức tự động của $x_{t}$ có thể được viết là:
$$\gamma(h)= cov (x_{t+h},x_{t})= \sigma_w^{2}\displaystyle\sum_{j=0}^{\infty}\psi_{j}\psi_{j+h}, h \geq 0.$$
Sau đó, chúng ta có thể sử dụng (3,36) và (3,37) để giải quyết các $\psi-weights$. Đổi lại, chúng ta có thể giải cho $\gamma(h)$ và ACF $\rho(h)=\gamma(h)/\gamma(0).$ Như trong ví dụ 3.8, cũng có thể có được phương trình sai phân đồng nhất trực tiếp theo $\gamma(h)$. Đầu tiên, chúng tôi viết:
\begin{align*}
\gamma(h) & = cov (x_{t+h},x_{t}) = E\Bigg[\bigg(\displaystyle\sum_{j=1}^{p} \theta_{j}w_{t+h-j}\bigg)x_{t}\Bigg]\\
&  = \displaystyle\sum_{j=1}^{p}\phi_{j}\gamma(h-j)+\sigma_w^{2}\displaystyle\sum_{j=h}^{q}\theta_{j}\psi_{j-h}, h \geq 0,\\
\end{align*}
trong đó chúng ta đã sử dụng thực tế là $x_{t}=\sum_{k=0}^{\infty}\psi_{k}w_{t-k}$ và với $h \geq 0$,
$$E(w_{t+h-j}x_{t})= E\Bigg[w_{t+h-j}\Big(\displaystyle\sum_{k=0}^{\infty}\psi_{k}w_{t-k}\Big)\Bigg] = \psi_{j-h}\sigma_w^{2}.$$
Từ (3,41), chúng ta có thể viết phương trình đồng nhất chung cho ACF của quy trình ARMA nguyên nhân:
$$\gamma(h)-\phi_{1}\gamma(h-1)-...-\phi_{p}\gamma(h-p) = 0, h \geq max(p,q +1),$$
với điều kiện ban đầu
$$\gamma(h)-\displaystyle\sum_{j=1}^{p}\phi_{j}\gamma(h-j) = \sigma_w^{2}\displaystyle\sum_{j=h}^{q}\phi_{j}\psi_{j-h}, 0 \leq h < max(p,q+1)$$
Chia (3,42) và (3,43) cho đến $\gamma(0)$ cho phép chúng tôi giải quyết ACF, $\rho(h) = \gamma(h)/\gamma(0)$.
\subsubsection*{Chức năng tự tương quan một phần (PACF - Partial AutoCorrelation Function)}
Chúng ta đã thấy trong (3.39), đối với các mô hình MA (q), ACF sẽ bằng 0 đối với độ trễ lớn hơn q. Hơn nữa, vì $0q=0$, ACF sẽ không bằng $0$ tại độ trễ $q$. Do đó, ACF cung cấp một lượng thông tin đáng kể về thứ tự của sự phụ thuộc khi quy trình là một quy trình trung bình di chuyển. Tuy nhiên, nếu quá trình là ARMA hoặc AR, thì ACF chỉ cho chúng ta biết rất ít về các mệnh lệnh phụ thuộc. Do đó, đáng để theo đuổi một chức năng sẽ hoạt động giống như ACF của các mô hình MA, nhưng đối với các mô hình AR, cụ thể là chức năng tự tương quan một phần (PACF).
\begin{align*}
 \gamma(2) = cov(\phi x_{t-1} + w_{t}, x_{t-2}) & = cov(\phi x_{t-1}+x_{t-2})\\
 & = cov(\phi^{2}x_{t-2}+\phi w_{t-1}+w_{t},x_{t-2})= \phi^{2}\gamma(0).\\
\end{align*}
Kết quả này xuất phát từ quan hệ nhân quả vì $x_{t-2}$ liên quan đến ${w_{t-2},w_{t-3},... }$, tất cả đều không tương thích với $w_{t}$ và $w_{t-1}$. Mối tương quan giữa $x_{t}$ và $x_{t-2}$ không bằng 0, vì nó sẽ là một MA (1), bởi vì $x_{t}$ phụ thuộc vào $x_{t-2}$ đến $x_{t-1}$. Giả sử chúng ta phá vỡ chuỗi phụ thuộc này bằng cách loại bỏ (hoặc tách ra) $x_{t-1}$. Đó là, chúng tôi xem xét mối tương quan giữa $x_{t}-\phi x_{t-1}$ và $x_{t-2}-\phi x_{t-1}$, vì đó là mối tương quan giữa $x_{t}$ và $x_{t-2}$, với sự phụ thuộc tuyến tính của từng loại trên $x_{t-1}$ đã bị loại bỏ. Theo cách này, chúng tôi đã phá vỡ chuỗi phụ thuộc giữa $x_{t}$ và $x_{t-2}$. Trong thực tế, 
$$cov(x_{t}-\phi x_{t-1},x_{t-2}-\phi x_{t-1}) = cov(w_{t},x_{t-2}-\phi x_{t-1}) = 0.$$
Để chính thức xác định PACF cho chuỗi thời gian dừng trung bình bằng 0, cho $x_1^{h-1}$ biểu thị hồi quy của $x_{h}$ trên ${x_{h-1}, x_{h-2},...,x_{1}}$, mà chúng ta viết là 
$$x_h^{h-1}= \beta_{1}x_{h-1}+\beta_{2}x_{h-2}+...+\beta_{h-1}x_{1}.$$
Không có thuật ngữ chặn là cần thiết trong (3.47) vì giá trị trung bình của $x_{t}$ bằng không. Ngoài ra, hãy cho $x_0^{h-1}$ biểu thị hồi quy của $x_{0}$ trên ${x_{1},x_{2},...,x_{h-1}}$, khi đó 
$$x_0^{h-1} = \beta_{1}x_{1}+\beta_{2}x_{2}+...+\beta_{h-1}x_{h-1}.$$
Các hệ số $\beta_{1},...,\beta_{h-1}$ giống nhau ở (3,47) và (3,48); chúng tôi sẽ giải thích kết quả này trong phần tiếp theo.
\begin{dn}\textbf{Hàm tự tương quan một phần - PACF} của một quá trình đứng yên $x_{t}$, ký hiệu là $\phi_{hh}$, với $h=1,2,...$ là
	$$\phi_{11}=corr(x_{1},x_{0})=\rho(1)$$
và
$$\phi_{hh} = corr(x_{h}-x_h^{h-1}, x_{0}-x_0^{h-1}), h \geq 2. $$
\end{dn}
Trong phần tiếp theo, chúng ta sẽ thảo luận về các phương pháp tính toán PACF. Các mô hình PACF cho MA hoạt động giống như các mô hình ACF cho các mô hình AR. Ngoài ra, PACF cho các mô hình AR hoạt động giống như các mô hình ACF cho MA. Do mô hình ARMA không thể đảo ngược có đại diện AR vô hạn, PACF sẽ không bị cắt. Chúng tôi mô tả kết quả vào bảng sau
\begin{center}
\begin{tabular}{ |c|c|c|c| }
	\hline
	& AR(p) & MA(q) & ARMA(p,q)\\
	\hline
	\hline
	ACF & Tails off & Cuts off after lag q &  Tails off\\
	PACF&   Cuts off after lag p  & Tails off & Tails off\\
	\hline
\end{tabular}
\end{center}

\subsection{Dự đoán}
Trong dự báo, mục tiêu là dự đoán các giá trị trong tương lai của chuỗi thời gian, $x_{n} + m $ m =1, 2 ,. . ., dựa trên dữ liệu được thu thập cho đến hiện tại, $x = {x_{n}, x_{n1},. . . , x_{1}}$. Trong suốt phần này, chúng ta sẽ giả sử xt là ổn định và các tham số mô hình đã biết. Vấn đề dự báo khi các tham số mô hình là chưa biết sẽ được thảo luận trong phần tiếp theo; Ngoài ra, xem Bài toán 3.25. Các dự báo lỗi bình phương trung bình tối thiểu của $x_{n} + m$ là 
$$ x_{n+m}^n= E (x_{n+m}\mid x_{n}, x_{n-1},...,x_{1})$$
bởi vì kỳ vọng có điều kiện giảm thiểu sai số bình phương trung bình $$E[x_{n+m} - g(x)]^2$$
Trong đó g (x) là một hàm của các quan sát x; xem bài toán 3.13.
Đầu tiên, chúng tôi sẽ hạn chế sự chú ý đến các yếu tố dự đoán là các hàm tuyến tính của dữ liệu, nghĩa là các yếu tố dự đoán theo dạng
$$x_{n+m}^n =\alpha_{0} + \sum_{k=1}^{n} \alpha_{k} x_{k}$$
trong đó $\alpha_{0}, \alpha_{1} ,. . . , \alpha_{n}$ là số thực. Dự đoán tuyến tính theo mẫu (3.52)
mà giảm thiểu lỗi dự đoán bình phương trung bình (3.51) được gọi là dự đoán tuyến tính tốt nhất  (BLPs). Như chúng ta sẽ thấy, dự đoán tuyến tính chỉ phụ thuộc vào quá trình thứ hai của moment, dễ dàng ước tính từ dữ liệu. Phần lớn tài liệu trong phần này được tăng cường bởi các tài liệu lý thuyết được trình bày trong Phụ lục B. Ví dụ, Định lý B.3 nêu rõ rằng nếu quy trình là Gaussian, dự báo lỗi bình phương trung bình tối thiểu và dự đoán tuyến tính tốt nhất giống nhau. Các định lý sau, dựa trên định lý phép chiếu, Định lý B.1 của Phụ lục B, là kết quả chính.
\begin{tc} Dự đoán tuyến tính tốt nhất cho các quy trình dừng
	
	Cho dữ liệu $x_{1},..., x_{n},$ công cụ dự đoán tuyến tính tốt nhất, $x_{n+m}^n= \alpha_{0} + \sum_{k=1}^{n}\alpha_{k} x_{k}$ với $m\geq1$ được tìm thấy bằng cách giải:
	$$ E[(x_{n+m} - x_{n+m}^n)x_{k}] = 0; k=0,1,...,n.$$ 
	Trong đó $x_{0}=1$
	Các phương trình quy định trong (3.53) được gọi là phương trình dự đoán và chúng được sử dụng để giải các hệ số ${\alpha_{0}, \alpha_{1} ,. . . ,\alpha_{n}}$. Nếu $E(x_{t}) =\mu $, phương trình đầu tiên (k = 0) của (3.53) suy ra
	$$E(x_{n+m}^n)= E (x_{n+m})= \mu$$
	Do đó, lấy kỳ vọng ở (3.52), chúng ta có
	$$\mu= \alpha_{0} + \sum_{k=1}^{n} \alpha(x_{k}- \mu)$$
	Vì vậy, cho đến khi chúng tôi thảo luận về ước tính, không có sự mất tính tổng quát trong việc xem xét trường hợp = 0, trong trường hợp đó, $\alpha_{0} = 0.$
	Hãy xem xét, đầu tiên, dự đoán trước một bước. Đó là, đã cho ${x_{1},. . . , x_{n}}$, chúng tôi muốn dự báo giá trị của chuỗi thời gian tại thời điểm tiếp theo, $x_{n} + 1$. Các BLP của $x_{n} + 1$ là
	$$ x_{n+1}^n = \phi_{n1}x_{n}+ \phi_{n2}x_{n-1}+...+ \phi_{nn}x_{1}, $$
	trong đó, với mục đích sẽ sớm trở nên rõ ràng, chúng tôi đã viết $\alpha_{k}$ trong (3.52) như n, n + 1 k trong (3.54), với k = 1 ,. . . , n. Sử dụng tính chất  P3.3, các hệ số
	${\phi_{1}, \phi_{2},. . . ,\phi_{n}}$ thỏa mãn
	$$E [(X_{n+1} - \sum_{j=1}^{n} \phi_{nj}x_{n+1-j})x_{n+1-k}] =0, k=1,..n.$$
	Các phương trình dự đoán (3.55) có thể được viết bằng ký hiệu ma trận như
	$$\Gamma_{n}\phi_{n}= \gamma_{n}$$
	
	Ma trận $\Gamma_{n}$ là không xác định. Nếu n là số ít, có nhiều giải pháp cho (3.56), nhưng, theo định lý hình chiếu (Định lý B.1), $x_{n+1}$ là độc nhất. Nếu n là số không, thì các phần tử của n là duy nhất và được cho bởi
	$$\phi_{n}= \Gamma_{n}^{-1}\gamma_{n}$$
	Đối với các mô hình ARMA, thực tế là $\delta^{2}_{w}\geq 0$ và $(h) \rightarrow 0$ là h đủ để đảm bảo rằng $\Gamma$ là xác định dương (Bài 3.11). Nó đôi khi thuận tiện để viết dự báo trước một bước trong ký hiệu vectơ
	$$x^{n}_{n+1}= \phi_{n}^{,}x$$
	với mọi $x= (x_{n}, x_{n-1},...,x_{1})^{,} $
	Lỗi dự đoán trung bình một bước trước là
	$$P_{n+1}^{n} = E (x_{n+1} - x_{n+1}^{n})^{2} = \gamma(0) - \Gamma^{,}_{n}\gamma_{n}$$	
	$$E(x_{n+1}- x_{n+1}^{n})^{2} = E(x_{n+1} - \phi_{n}^{,}x)^{2}= E(x_{n+1} - \Gamma^{,}_{n}x)^{2}= E(x_{n+1}^{2} - 2\gamma^{,}_{n}\Gamma^{-1}_{n}xx_{n+1} + \gamma^{,}_{n}\Gamma^{-1}_{n}xx^{,}\Gamma^{-1}_{n\gamma_{n}})=\gamma(0) -2\gamma^{,}_{n}\Gamma^{-1}_{n}xx_{n+1} + \gamma^{,}_{n}\Gamma^{-1}_{n}xx^{,}\Gamma^{-1}_{n\gamma_{n}}) $$	
\end{tc}
\begin{tc}
	Thuật toán  Durbin- Levinson
	Phương trình (3.57) và (3.59) có thể được giải quyết lặp lại như sau: $$\phi_{00}= 0 , P_{1}^{0}= \gamma(0)$$
	Cho $n\geq 1$ 
	$$\phi_{nn} = \dfrac{\rho(n) - \sum_{k-1}^{n-1}\phi_{n-1,k}\rho
		(n-k)}{1- \sum_{k-1}^{n-1}\phi_{n-1,k}\rho(k)}, P_{n+1}^{n}= P_{n}^{n-1}(1 - \phi_{nn}^{2})$$
	Cho $n\geq 2$
	$$\phi_{nk} = \phi_{n-1,k}- \phi_{nn}\phi_{n-1,n-k},  k=1,2,...,n-1$$
\end{tc}
\begin{tc}
	Giải pháp lặp cho PACF
	PACF của một quá trình ổn định $x_{t}$, có thể được lặp đi lặp lại qua (3,62) như $\phi_{nn}$, với n= 1,2,...
	Cho đến nay, chúng tôi đã tập trung vào dự đoán trước một bước, nhưng tính chất P3.3 cho phép chúng ta tính BLP của $x_{n+m}$ cho mọi $m \geq 1$. Cho dữ liệu, $(x_{1} ,. . . , x_{n})$, công cụ dự đoán trước một bước là
	$$x_{n+m}^{n}= \phi_{n1}^{(m)}x_{n} +\phi_{n2}^{(m)}x_{n-1}+...+\phi_{nn}^{(m)}x_{1}$$
	với $\{\phi_{n1}^{(m)}, \phi_{n2}^{(m)},...,\phi_{nn}^{(m)}\}$ thỏa mãn phương trình:
	$$ \sum_{j=1}^{n}\phi_{nj}^{(m)}E(x_{n+1-j}x_{n+1-k})= E (x_{n+m}x_{n+1-k}), k= 1,...,n$$
	hoặc 
	$$\sum_{j=1}^{n}\phi_{nj}^{(m)}\gamma(m+k-1), k=1,...,n$$ 
	Các phương trình dự đoán một lần nữa có thể được viết bằng ký hiệu ma trận như
	$$\Gamma_{n}\phi_{n}^{(m)}= \gamma_{n}^{(m)}$$
	với $\gamma_{n}^{(m)}= (\gamma(m),...,\gamma(m+n-1))^{'}$
	và $\phi_{n}^{(m)} = (\phi_{n1}^{(m)},...,\phi_{nn}^{(m)})^{'}$ là $n\times 1$ vectơ
	Lỗi dự đoán trung bình m-step-before trung bình là
	$$P_{n+m}^{n} = E (x_{n+m}- x_{n+m}^{n})^{2} = \gamma(0) - \gamma_{n}^{(m)^{'}}\Gamma_{n}^{-1}\gamma_{n}^{(m)}$$
	Một thuật toán hữu ích khác để tính toán dự báo được đưa ra bởi Brockwell và Davis (1991, Chương 5). Thuật toán này theo sau trực tiếp từ việc áp dụng định lý hình chiếu (Định lý B.1) cho các đổi mới, $x_{t} - x_{t}^{t-1}$, cho t = 1 ,. . . , n, sử dụng thực tế là các đổi mới $x_{t} - x_{t}^{t-1}$ và $x_{s} - x_{s}^{s-1}$ là không tương quan cho $s \neq t$ (xem Bài toán 3.39). Chúng tôi trình bày trường hợp trong đó $x_{t}$ là một chuỗi thời gian dừng trung bình bằng không.
	
\end{tc}
\begin{tc}
	Thuật toán đổi mới	
	Các dự đoán trước một bước, $x_{t+1}^{t}$ và các lỗi bình phương trung bình của chúng, $P_{t+1}^{t}$, có thể được tính toán lặp đi lặp lại như
	$$x_{1}^{0}=0, P_{1}^{0} =\gamma(0)$$
	$$x_{t+1}^{t} = \sum_{j=1}^{t}\theta_{tj}(x_{t+1-j} - x_{t+1-j}^{t-j}), t= 1,2...$$
	$$P_{t+1}^{t} = \gamma(0) - \sum_{j=0}^{t}\theta^{2}_{t,t-j}P_{j+1}^{j}, j=1,2,..$$
	cho $j=0,1,...t-1,$
	$$\theta_{t,t-j}= (\gamma(t-j) - \sum_{k=0}^{j-1}\theta_{j,j-k}\theta_{t,t-k}P_{k+1}^{k})(P_{j+1}^{j}).$$
	Cho dữ liệu $x_{1} ,. . . , x_{n}$, thuật toán đổi mới có thể được tính liên tiếp với $t = 1$, sau đó $t = 2, v.v.,$ trong trường hợp đó, phép tính của $x^{n}_{n+1}$ và $P^{n}_{n+1}$ được thực hiện ở bước cuối cùng $t = n$. Công cụ dự đoán m-step-head và lỗi bình phương trung bình của nó dựa trên thuật toán đổi mới (Bài toán 3.39) là được cho bởi
	$$x_{n+1}^{n} = \sum_{j=m}^{n+m-1}\theta_{n+m-1,j}(x_{n+m-j}- x^{n+m-j-1}_{n+m-j}),$$
	$$P_{n+m}^{n}=  \gamma(0) - \sum_{j=m}^{n+m-1}\theta^{2}_{n+m-1}P_{n+m-j}^{n}$$
	trong đó $\theta_{n+m-1,j}$ thu được bằng cách lặp lại liên tục của (3,70)
\end{tc}
\subsection*{Dự báo quy trình của ARIMA}
Các phương trình dự đoán chung (3.53) cung cấp ít kiến thức về dự báo cho các mô hình ARMA nói chung. Có một số cách khác nhau để thể hiện những dự báo này và mỗi phương tiện để hiểu sự dự đoán cấu trúc đặc biệt của ARMA. Chúng ta giả sử $x_{t}$ là một ARMA(p, q), nhân quả và không thể đảo ngược quá trình   $\phi(B)x_{t} = \theta(B)w_{t}$ trong đó $w_{t} \sim iid N(0,\delta_{w}^{2})$. Trong trường hợp trung bình khác không, $E(x_{t})=\mu$, chỉ cần thay $x_{t}$ $x_{t}-\mu$ trong mô hình. Đầu tiên, chúng tôi xem xét hai loại dự báo. Chúng tôi viết $x_{n+m}^{n}$ có nghĩa là dữ báo lỗi bình phương trung bình tối thiểu của $x_{n+m}$ dựa trên dữ liệu $\{x_{n},...,x_{1}\}$, nghĩa là $$x_{n+m}^{n} = E(x_{n+m}|x_{n},...x_{1}).$$

Đối với các mô hình ARMA, việc tính toán dự đoán $x_{n+m}$ sẽ dễ dàng hơn, giả sử chúng ta có lịch sử đầy đủ của quá trình $\{x_{n},x_{n-1},...\}$ Chúng tôi sẽ biểu thị dự đoán của $x_{n+m}$ dựa trên quá khứ vô hạn như: 
$$\overline{x}_{n+m} = E(x_{n+m}|x_{n},...x_{1}).$$
Ý tưởng ở đây là, đối với các mẫu lớn, $\overline{x}_{n+m}$ sẽ cung cấp một xấp xỉ tốt đến $x_{n+m}^{n}$  
Bây giờ, $x_{n+m}$ dưới dạng nhân quả và khả nghịch:
$$x_{n+m}= \sum_{j=0}^{\infty} \psi_{j}w_{n+m-j}, \psi_{0}=1$$
$$w_{n+m}= \sum_{j=0}^{\infty} \pi_{j}x_{n+m-j}, \pi_{0}=1$$
Sau đó, lấy kỳ vọng có điều kiện trong (3.73), chúng ta có
$$ \overline{x}_{n+m} =\sum_{j=0}^{\infty}\psi_{j}w_{n+m-j},$$
bởi vì, bởi (3,74),
$$\overline{w}_{t}\equiv E(w_{t}|x_{n},x_{n-1},..) = $$
Tương tự, lấy kỳ vọng có điều kiện trong (3,74), chúng ta có
$$0 = \overline{x}_{n+m} + \sum_{j=1}^{\infty} \pi_{j}\overline{x}_{n+m-j}$$
hoặc
$$\overline{x}_{n+m} = -\sum_{j=1}^{m-1}\pi_{j}\overline{x}_{n+m-j}- \sum_{j=m}^{\infty}\pi_{j}x_{n+m-j},$$
sử dụng thực tế $E(x_{t}|x_{n},x_{n-1},...)= x_{t}$ với $t \leq n$. Dự đoán được thực hiện sử dụng hồi quy (3.76), bắt đầu bằng công cụ dự đoán trước một bước, $m = 1$, và sau đó tiếp tục cho $m = 2, 3 ,. . ..$ Sử dụng (3,75), chúng ta có thể viết
$$x_{n+m} - \overline{x}_{n+m} = \sum_{j=0}^{m-1}\psi_{j}w_{n+m-j}$$
vì vậy dự đoán  lỗi bình phương trung bình có thể được viết là
$$P_{n+m}^{n}= E(x_{n+m} - \overline{x}_{n+m})^{2}= \delta^{2}_{w} \sum_{j=0}^{m-1}\psi_{j}^{2}$$
Ngoài ra, chúng tôi lưu ý, đối với một cỡ mẫu cố định, n, các dự đoán  lỗi có tương quan.
Đó là, với $ k\geq 1$
$$E\{(X_{n+m}- \overline{x}_{n+m})(x_{n+m+k} - \overline{x}_{n+m+k})\}= \delta_{w}^{2}\sum_{j=0}^{m-1}\psi_{j}\psi_{j+k}$$
Khi $n$ nhỏ, các phương trình dự đoán chung (3.53) có thể được sử dụng dễ dàng. Khi $n$ lớn, chúng ta sẽ sử dụng (3.76) bằng cách sai số, vì chỉ có dữ liệu có sẵn. Trong trường hợp này, chúng ta có thể sai số (3,76) bằng cách đặt $\sum_{j=n+m}^{\infty} \pi_{j}\ x_{n+m-j}= 0$. Dự đoán sai số sau đó được viết là
$$\tilde{x}^{n}_{n+m}= - \sum_{j=1}^{m-1}\pi_{j}\tilde{x}_{n+m-j}^{n} - \sum_{j=n}^{n+m-1}\pi_{j}.x_{n+m-j} ,$$
cũng được tính toán hồi quy, $m = 1, 2 ,...$ Dự đoán lỗi bình phương trung bình, trong trường hợp này, được tính gần đúng bằng cách sử dụng (3.77).

Đối với các mô hình AR(p) và khi $n> p$, phương trình (3,60) mang lại dự đoán chính xác $x^{n}_{n+m}$, của $x_{n+m}$ và không cần xấp xỉ. Đó là, cho $n> p$ , $\tilde{x}_{n+m}^{n}=\tilde{x}_{n+m}=x^{n}_{n+n}$. Ngoài ra, trong trường hợp này, dự đoán lỗi trước một bước là  $E(x_{n+1} - x_{n+1}^{n})^{2}=\sigma^{2}_{w}$. Đối với các mô hình ARMA $(p, q)$ chung, dự đoán sai số (Bài 3.15) cho $m = 1, 2 ,...$ là
$$\tilde{x}^{n}_{n+m}=\phi_{1}\tilde{x}^{n}_{n+m-1}+...+ \phi_{p}\tilde{x}^{n}_{n+m-p}+ \theta_{1}\tilde{w}^{n}_{n+m-1}+...+\theta_{q}\tilde{w}^{n}_{n+m-q},$$
trong đó $\tilde{x}_{t}^{n}=x_{t}$ cho $1\leqslant t \leqslant n$ và $\tilde{x}^{n}_{t}=0$ với $t\leqslant0$. Dự đoán lỗi sai số được đưa ra bởi: $\tilde{w}_{t}^{n}=0$ với $t\leqslant0$ hoặc $t>n$ và $\tilde{w}_{t}^{n}=\phi(B)\tilde{x}_{t}^{n}-\theta_{1} \tilde{w}_{t-1}^{n}-...-\theta_{q}\tilde{w}_{t-q}^{n}$ cho $ 1 \leq t \leq n $ 

Để đánh giá độ chính xác của các dự báo, các khoảng tin cậy thường là tính toán cùng với các dự báo. Nói chung, $ (1-\alpha) $ khoảng tin cậy có dạng 
$$ x_{n+m}^n \pm c_{a/2} \sqrt{p_{n+m}^n} $$

Trong đó $ c_{a/2} $ được chọn để có được mức độ tự tin mong muốn. Ví dụ, nếu quá trình là Gaussian, sau đó chọn $ c_{a/2} = 2 $ sẽ mang lại khoảng dự đoán xấp xỉ 95 cho $x_{n+m}$ . 
Nếu chúng ta quan tâm đến việc thiết lập dự đoán các khoảng tin cậy hơn một khoảng thời gian, sau đó nên điều chỉnh $ c_{a/2} $ một cách thích hợp.

Chúng tôi hoàn thành phần này với một cuộc thảo luận ngắn gọn về backcasting. Trong backcasting, chúng tôi muốn dự đoán $ x_{1-m} $, $ m=1,... $ , dựa trên dữ liệu $ \left\lbrace x_{1},...,x_{n} \right\rbrace $ 

Viết backcast như
$$x_{1=m}^n=\sum_{j=1}^{n}\alpha_{j}x_{j}$$
Tương tự với (3,65), các phương trình dự đoán (giả sử $ \mu = 0 $) là 
$$\sum_{j=1}^{n}\alpha_{j}E(x_{j}x_{k})=E(x_{1-m}x_{k}), k=1,...,n$$
hoặc 
$$\sum_{j=1}^{n}\alpha_{j}\gamma(k-j)=\gamma(m+k-1), k=1,...,n$$
Các phương trình này chính xác là các phương trình dự đoán cho dự đoán về phía trước $ \alpha_{j}\equiv \phi_{nj}^{(m)} $ cho $ j=1,..,n $ trong đó $ \phi_{nj}^{(m)} $ đưuọc cho bởi(3.66)

Cuối cùng, backcast được đưa ra bởi
$$ x_{1=m}^n= \phi_{n1}^{(m)}x_{1}+...+\phi_{nn}^{(m)}x_{n}, m=1,2,... $$

\subsection{Ước lượng}
	Trong suốt phần này, chúng tôi giả sử chúng tôi có $ n $ quan sát, $ x_{1} ,. . . , x_{n} $, từ một quá trình $ ARMA Gaussian (p, q) $  nhân quả và không thể đảo ngược, trong đó, ban đầu, tham số thứ tự, $ p $ và $ q $, được biết đến. Mục tiêu của chúng tôi là ước tính các tham số , $ \phi_{1} ,. . . , \phi_{p}, \theta_{1} ,. . . ,\theta_{p}  $ và $ \sigma_{\omega}^2 $ 

Chúng tôi sẽ thảo luận về vấn đề xác định p và q sau này trong phần này.
Chúng tôi bắt đầu với phương pháp ước tính moments . Ý tưởng đằng sau những người ước tính này là đánh đồng các moments tổng thể  với các moments mẫu và sau đó giải quyết các tham số về các moments mẫu. Chúng tôi ngay lập tức thấy rằng, nếu $ E(x_{t})=\mu $. thì phương pháp ước lượng moments của $ \mu $ là trung bình mẫu, $ \bar{x} $. Vì vậy, trong khi thảo luận về phương pháp moments, chúng ta sẽ giả sử $ \mu=0 $. Mặc dù phương pháp moments có thể tạo ra các công cụ ước tính tốt, đôi khi chúng có thể dẫn đến các công cụ ước tính dưới mức tối ưu. Trước tiên chúng tôi xem xét trường hợp trong đó phương pháp dẫn đến các công cụ ước tính (hiệu quả) tối ưu, đó là mô hình $ AR(p) $.

Khi quá trình là $ AR(p) $
$$x_{t}=\phi_{1}x_{t-1}+...+\phi_{p}x_{t-p}+\omega_{t} $$
Đầu tiên các phương trình $ p + 1 $ của (3,42) và (3,43), $ h = 0, 1 ,. . . , p $, dẫn đến
tiếp theo:
\begin{dn}
	Phương trình Walker Yule
	$$ \gamma(h)=\phi_{1}\gamma_{h-1}+...+\phi_{p}\gamma_{h-p} , h = 0, 1 ,. . . , p $$
	$$ \sigma_{\omega}^2=\gamma(0) - \phi_{1}\gamma_{1}-...-\phi_{p}\gamma_{p}  $$
	
\end{dn}
Trong ký hiệu ma trận, các phương trình Yule của Walker là
$$ \Gamma_{p}\phi=\gamma_{p}, \sigma_{\omega}^2=\gamma_{0}-\phi^{'}\gamma_{p} $$
trong đó $ \Gamma_{p}\left\lbrace \gamma(k-j)\right\rbrace_{j,k=1}^p  $ là ma trận $ p \times p, \varphi=(1,...,p) $ là một vecto $ p \times 1 $, và $ \gamma_{p}=(\gamma(1),...,\gamma(p))^{'} $ là một vecto $ p\times1 $ . Sử dụng phương pháp moments, chúng tôi thay $ \gamma(h) $ trong (3.90) bằng $ \hat{\gamma}(h) $  [xem phương trình (1.36)] và giải
$$ \hat{\phi}=\hat{\Gamma}_{p}^{-1}\hat{\gamma}_{p},  \hat{\sigma}_{\omega}^2=\hat{\gamma}(0)-\phi^{'}\hat{\Gamma}_{p}^-1\hat{\gamma}_{p} $$
Các công cụ ước tính này thường được gọi là công cụ ước tính Walker Yule. Để tính toán mục đích, đôi khi thuận tiện hơn khi làm việc với ACF mẫu.
Bằng nhân tố $ \hat{\Gamma}(0) $ trong (3,91), chúng ta có thể viết ước tính Yule Walker như sau
$$ \hat{\phi}=\hat{R}_{p}^-1\hat{\rho}_{p}, \hat{\sigma}_{\omega}^2=\hat{\gamma}(0)[1-\hat{\rho}_{p}^{\prime} \hat{R}_{p}^-1\hat{\rho}_{p}] $$
Trong đó $ \hat{R}_{p}=\left\lbrace\hat{p}(k-j)\right\rbrace _{j,k=1}^p  $ là ma trận $p\times p$ và $\hat{\rho}_{p}=(\hat{\rho}_{1},...\hat{\rho}_{p})^{\prime}  $ là một vector $ p\times 1 $.

Đối với các mô hình AR ($ p $), nếu kích thước mẫu lớn, công cụ ước tính Walker Yule gần với phân phối chuẩn và $ \hat{\sigma}_{\omega}^2 $ gần với giá trị thực của $ \sigma_{\omega}^2 $. Chúng tôi nêu những kết quả này trong định lý P3.7.
\begin{theo}
	Kết quả mẫu lớn cho Công cụ ước tính Walker Yule
	
	Hành vi tiệm cận $ (n \longrightarrow\infty) $ của các công cụ ước tính Walker Yule trong trường hợp của các quá trình AR ($ p $) nhân quả như sau:
	\begin{center}
		$\sqrt{n}(\hat{\phi}-\phi) \xrightarrow{d} N(0,\sigma_{\omega}^2\Gamma_{p}^-1)$,  $\hat{\sigma}_{\omega}^2 \xrightarrow{p} \sigma_{\omega}^2$
	\end{center}  
	
\end{theo}
Thuật toán  Durbin- Levinson, (3,61) - (3,63), có thể được sử dụng để tính $ \hat{\phi} $ mà không đảo ngược $ \hat{\Gamma}_{p} $ hoặc $ \hat{R}_{p} $ bằng cách thay $ \gamma(h) $ bằng $ \hat{\gamma}(h) $ trong thuật toán.  

Trong chạy thuật toán, chúng tôi sẽ tính toán lặp lại vectơ $ h \times 1 $, $\hat{\phi}_{h}=(\hat{\phi}_{h1},...\hat{\phi}_{hh})^{\prime}  $ với $ h = 1, 2 ,... $ . Vì vậy, ngoài việc đạt được mong muốn dự báo, thuật toán Durbin-Levinson mang lại trường $ \hat{\phi}_{hh} $ PACF mẫu. Sử dụng (3,93), chúng tôi chỉ ra các tính chất sau.
\begin{theo}
	Phân phối mẫu lớn của PACF
	Đối với quá trình AR (p) nhân quả, tiệm cận $ (n \longrightarrow\infty) $
	\begin{center}
		$\sqrt{n}\hat{\phi}_{hh} \xrightarrow{d} N(0,1)$, cho $h>p  $
	\end{center}
	
\end{theo}
\begin{theo}
	Phân phối mẫu lớn của Công cụ ước tính
	
	Trong các điều kiện thích hợp, đối với các quá trình ARMA nhân quả và không thể đảo ngược, khả năng tối đa, bình phương tối thiểu vô điều kiện và công cụ ước lượng bình phương tối thiểu có điều kiện, mỗi công cụ được khởi tạo bằng phương pháp ước lượng Moments, tất cả cung cấp các ước tính tối ưu của $ \sigma_{\omega}^2 $ và  $ \beta $  , theo nghĩa $ \hat{\sigma}_{\omega}^2 $   là phù hợp, và phân phối tiệm cận của là phân phối chuẩn tiệm cận tốt nhất. Cụ thể, như $ (n \longrightarrow\infty) $
	$$\sqrt{n}(\hat{\beta}-\beta) \xrightarrow{d} N(0,\sigma_{\omega}^2\Gamma_{p,q}^-1)$$
	
\end{theo}
Trong (3.118), ma trận hiệp phương sai phương sai của công cụ ước lượng $ \hat{\beta} $ là nghịch đảo của ma trận thông tin. Trong trường hợp này, ma trận $ (p + q) \times (p + q) $ $ \Gamma_{p,q} $ có hình thức
$$ \Gamma_{p,q}= \begin{pmatrix}
\Gamma_{\phi,\phi}  & \Gamma_{\phi,\theta} \\
\Gamma_{\theta,\phi}  & \Gamma_{\theta,\theta}
\end{pmatrix} $$
Ma trận $ p \times p $  $ \Gamma_{\phi,\phi}  $
được cho bởi (3.90), nghĩa là phần tử thứ $ ij $ của $ \Gamma_{\varphi,\varphi}  $ cho
$ i, j = 1 ,. . . , p $, là $ \gamma_{x}(i-j) $ từ quy trình AR ($ p $), $ \phi (B)x_{t}=\omega_{t} $. Tương tự $ \Gamma_{\phi,\phi} $ là ma trận $ q \times q $ với phần tử thứ $ ij $, bằng $ \gamma_{y}(i-j) $ từ một quá trình AR ($ q $), $ \theta(B)y_{t}=\omega_{t} $. Ma trận $ p \times q $, $ \Gamma_{\phi\theta} = \left\lbrace \gamma_{xy}(i-j)\right\rbrace  $. cho $ i = 1 ,. . . , p $; $ j = 1 ,. . . , q $; đó là, phần tử thứ $ ij $ là hiệp phương sai giữa hai quá trình AR được cho bởi $ \phi (B)x_{t}=\omega_{t} $ và $ \theta(B)y_{t}=\omega_{t} $ 

Cuối cùng, $ \Gamma_{\theta\phi}= \Gamma_{\phi\theta}^{\prime}$
\subsection{Mô hình tích hợp cho dữ liệu không có tính dừng}
	Trong Chương 1 và 2, chúng ta đã thấy rằng nếu $ x_{t} $ là bước đi ngẫu nhiên, $ x_{t}=x_{t-1}+\omega_{t} $ thì bằng khác biệt $ x_{t} $. Chúng tôi thấy rằng $ \bigtriangledown x_{t}=\omega_{t} $ là dừng. Trong nhiều tình huống, chuỗi thời gian có thể được coi là bao gồm hai thành phần, một thành phần xu hướng không có tính dừng và một thành phần tính dừng trung bình bằng không
\begin{dn}
	Một quá trình, $ x_{t} $ được gọi là ARIMA ($ p, d, q $) nếu 
	$$ \bigtriangledown^{d} x_{t}=(1-B)^{d}x_{t}$$
	là ARMA ($ p, q $). Nói chung, chúng tôi sẽ viết mô hình như 
	$$ \phi(B)(1-B)^{d}x_{t}=\theta(B)\omega_{t} $$
	Nếu $ E(\bigtriangledown^{d} x_{t})=\mu $ chúng ta viết mô hình là
	$$ \phi(B)(1-B)^{d}x_{t}=\alpha+\theta(B)\omega_{t} $$
	trong đó $ \alpha=\mu(1-\phi_{1}-..-\phi_{p}) $
\end{dn}
\subsection{Xây dựng mô hình ARIMA}
Có một vài bước cơ bản để khớp các mô hình ARIMA với dữ liệu chuỗi thời gian. Các bước này liên quan đến việc vẽ dữ liệu, có thể chuyển đổi dữ liệu, xác định thứ tự phụ thuộc của mô hình, ước tính tham số, chẩn đoán và lựa chọn mô hình. Đầu tiên, như với bất kỳ phân tích dữ liệu nào, chúng ta nên xây dựng một biểu đồ thời gian của dữ liệu và kiểm tra biểu đồ xem có bất kỳ sự bất thường nào không. Nếu, ví dụ, sự thay đổi trong dữ liệu tăng theo thời gian, sẽ cần phải chuyển đổi dữ liệu để ổn định phương sai. Trong những trường hợp như vậy, có thể sử dụng lớp biến đổi công suất của Box Box Cox, phương trình (2.34). Ngoài ra, ứng dụng cụ thể có thể đề xuất một chuyển đổi thích hợp. Ví dụ: giả sử một quá trình phát triển như một thay đổi phần trăm khá nhỏ và ổn định, chẳng hạn như đầu tư. Ví dụ: chúng ta có thể có:
$$x_{t}=(1+p_{t})x_{t-1},$$
tại $x_{t}$ là giá trị của khoản đầu tư tại thời điểm $t$ và $p_{t}$ là phần trăm thay đổi từ giai đoạn $t - 1$ thành $t$, có thể âm. Lấy $logs$ chúng ta có: 
$$ln(x_{t})= ln(1+p_{t}) + ln(x_{t-1}),$$
hoặc
$$\nabla[ln(x_{t})]= ln(1+p_{t}).$$
Nếu phần trăm thay đổi $p_{t}$vẫn tương đối nhỏ về độ lớn thì $ln(1+p_{t})\approx p_{t}$ và do đó, $$\nabla[ln(x_{t})]\approx p_{t},$$
sẽ là một quá trình tương đối ổn định. Thông thường, $\nabla[ln(x_{t})]$ được gọi là tỷ lệ hoàn vốn hoặc tăng trưởng. Ý tưởng chung này đã được sử dụng trong Ví dụ 3.31 và chúng tôi sẽ sử dụng lại trong Ví dụ 3.35.

Sau khi chuyển đổi dữ liệu một cách thích hợp, bước tiếp theo là xác định các giá trị sơ bộ của thứ tự tự phát, $p$, thứ tự khác biệt, $d$ và thứ tự di chuyển trung bình, $q$. Chúng tôi đã giải quyết, một phần, vấn đề chọn $d$. Một biểu đồ thời gian của dữ liệu thường sẽ gợi ý xem có cần phân biệt không. Nếu sự khác biệt được gọi là cho, thì hãy phân biệt dữ liệu một lần, $d = 1$ và kiểm tra biểu đồ thời gian của $\nabla x_{t}$. Nếu sự khác biệt bổ sung là cần thiết, sau đó thử phân biệt lại và kiểm tra biểu đồ thời gian của $\nabla^{2}x_{t}$. Hãy cẩn thận để không quá quan trọng bởi vì điều này có thể giới thiệu sự phụ thuộc nơi không tồn tại. Ví dụ: $x_{t}=w_{t}$ không tương quan, nhưng $\nabla x_{t} = w_{t}-w_{t-1}$ là MA(1). Ngoài các ô thời gian, ACF mẫu có thể giúp xác định xem có cần phân biệt hay không. Vì đa thức $\phi(z)(1-z)^{d}$ có một đơn vị gốc, ACF mẫu, $\hat{\rho}$ sẽ không phân rã về 0 nhanh khi $h$ tăng. Do đó, sự phân rã chậm trong $\hat{\rho}$ là một dấu hiệu cho thấy sự khác biệt có thể cần thiết. 

Khi các giá trị sơ bộ của $d$ đã được giải quyết, bước tiếp theo là xem xét ACF và PACF mẫu của $\nabla^{d}x_{t}$ cho bất cứ giá trị nào của $d$ đã được chọn. Sử dụng Bảng 3.1 làm hướng dẫn, các giá trị sơ bộ của $p$ và $q$ được chọn. Hãy nhớ lại rằng, nếu $p = 0$ và $q> 0$, ACF sẽ tắt sau khi trễ $q$ và PACF tắt. Nếu $q = 0$ và $p> 0$, PACF sẽ tắt sau khi lag $p$ và ACF tắt. Nếu $p> 0$ và $q> 0$, cả ACF và PACF sẽ tắt. Bởi vì chúng tôi đang xử lý các ước tính, sẽ không phải lúc nào cũng rõ liệu ACF hoặc PACF mẫu đang cắt đuôi hay cắt đứt. Ngoài ra, hai mô hình có vẻ khác nhau thực sự có thể rất giống nhau. Với suy nghĩ này, chúng ta không nên lo lắng về việc quá chính xác ở giai đoạn này của mô hình phù hợp. Ở giai đoạn này, một vài giá trị sơ bộ của $p$, $d$ và $q$ nên có sẵn và chúng ta có thể bắt đầu ước tính các tham số.

Bước tiếp theo trong mô hình phù hợp là chẩn đoán. Điều tra này bao gồm phân tích các phần dư cũng như so sánh mô hình. Một lần nữa, bước đầu tiên liên quan đến một biểu đồ thời gian của các đổi mới (hoặc phần dư), $x_{t}-\hat{x_{t}}^{t-1}$, hoặc của các đổi mới được tiêu chuẩn hóa
$$e_{t}= (x_{t}-\hat{x_{t}}^{t-1})/\sqrt[]{\hat{P_t^{t-1}}},$$
trong đó $\hat{x_{t}}^{t-1}$ là dự đoán trước một bước của $x_{t}$ dựa trên mô hình được trang bị và $\hat{P_t^{t-1}}$ là phương sai sai số trước một bước ước tính. Nếu mô hình phù hợp tốt, phần dư được chuẩn hóa sẽ hoạt động như một chuỗi iid với giá trị trung bình bằng 0 và phương sai. Biểu đồ thời gian nên được kiểm tra cho bất kỳ sự khởi hành rõ ràng nào từ giả định này. Trừ khi chuỗi thời gian là Gaussian, không đủ để phần còn lại không tương quan. Ví dụ, trong trường hợp không phải Gaussian có thể có một quy trình không tương quan với các giá trị tiếp giáp theo thời gian phụ thuộc cao. Ví dụ, chúng tôi đề cập đến họ các mô hình GARCH được thảo luận trong Chương 5.

Điều tra về tính bình thường cận biên có thể được thực hiện một cách trực quan bằng cách nhìn vào biểu đồ của phần dư. Ngoài ra, một biểu đồ xác suất bình thường hoặc một biểu đồ Q-Q có thể giúp xác định các lần khởi hành từ tính quy tắc. Xem Johnson và Wicéc (1992, Chương 4) để biết chi tiết về thử nghiệm này cũng như các thử nghiệm bổ sung cho tính quy phạm đa biến.

Có một số thử nghiệm về tính ngẫu nhiên, ví dụ thử nghiệm chạy, có thể được áp dụng cho các phần dư. Chúng tôi cũng có thể kiểm tra sự tự tương quan mẫu của phần dư, giả sử, $\hat{\rho_{e}(h)}$, cho bất kỳ mẫu hoặc giá trị lớn nào. Hãy nhớ lại rằng, đối với chuỗi nhiễu trắng, tự động tương quan mẫu xấp xỉ độc lập và thường được phân phối với phương tiện bằng $0$ và phương sai $1/n$. Do đó, một kiểm tra tốt về cấu trúc tương quan của phần dư là vẽ biểu đồ $\hat{\rho_{e}(h)}$ so với $h$ cùng với giới hạn lỗi là $\pm2/\sqrt{n}$. Phần dư từ một mô hình phù hợp, tuy nhiên, sẽ không hoàn toàn có các thuộc tính của chuỗi nhiễu trắng và phương sai của $\hat{\rho_{e}(h)}$ có thể nhỏ hơn $1/n$. Thông tin chi tiết có thể được tìm thấy trong Box and Pierce (1970) và McLeod (1978). Phần chẩn đoán này có thể được xem như là một kiểm tra trực quan của $\hat{\rho_{e}(h)}$ với mối quan tâm chính là việc phát hiện các sự khởi hành rõ ràng từ giả định độc lập. Ngoài âm mưu  $\hat{\rho_{e}(h)}$ chúng ta có thể thực hiện một bài kiểm tra tổng quát có tính đến độ lớn của $\hat{\rho_{e}(h)}$ như một nhóm. Ví dụ, có thể là trường hợp cá nhân, mỗi $\hat{\rho_{e}(h)}$ có độ lớn nhỏ, giả sử, mỗi cái chỉ nhỏ hơn một chút so với $2/\sqrt{n}$ về độ lớn, nhưng, gọi chung là các giá trị đều lớn. Thống kê Box Box Pi-Q được đưa ra bởi
$$Q = n(n+2)\displaystyle\sum_{h=1}^{H}\dfrac{\hat{\rho_{e}^{2}(h)}}{n-h}$$
có thể được sử dụng để thực hiện một bài kiểm tra như vậy. Giá trị H trong (3.138) được chọn một cách tùy ý, thông thường, $H = 20$. Theo giả thuyết khống về tính thỏa đáng của mô hình, không có triệu chứng $(n\rightarrow \infty)$, $Q\sim \chi_H-p-q^{2}$. Do đó, chúng tôi sẽ bác bỏ giả thuyết khống ở cấp độ $\alpha$ nếu giá trị của Q vượt quá $(1-\alpha)$ lượng tử của $\chi_H-p-q^{2}$ phân phối. Thông tin chi tiết có thể được tìm thấy trong Box and Pierce (1970), Ljung and Box (1978), và Davies et al. (1977).
\subsection{Mô hình ARIMA theo mùa}
		Trong phần này, chúng tôi giới thiệu một số dạng được thực hiện bởi mô hình ARIMA để giải thích cho xu hướngtheo mùa và không dừng. Thông thường, sự phụ thuộc vào quá khứ có xu hướng xảy ra mạnh mẽ nhất ở bội số của một số độ trễ theo mùa cơ bản. Ví dụ, với dữ liệu kinh tế hàng tháng, có một thành phần mạnh hàng năm xảy ra ở độ trễ là bội số của $s = 12$, vì mối quan hệ bền vững của toàn bộ hoạt động với năm dương lịch. Dữ liệu được lấy hàng quý sẽ thể hiện khoảng thời gian lặp lại hàng năm tại $s = 4$ quý. Hiện tượng tự nhiên như nhiệt độ cũng có các thành phần mạnh tương ứng với các mùa. Do đó, sự biến thiên tự nhiên của nhiều quá trình vật lý, sinh học và kinh tế có xu hướng phù hợp với biến động theo mùa. Chính vì điều này, nó thích hợp để giới thiệu các đa thức tự hồi quy, trung bình trượt xác định với độ trễ theo mùa. Mô hình tự hồi quy trung bình trượt theo mùa thuần túy, giả sử, ARMA $(P,Q)_{s}$, sau đó có dạng
$$\Phi_{P} (B^{s})x_{t}=\varTheta_{Q}(B^{s})w_{t}$$
30/5000
với định nghĩa sau.

\begin{dn}	
	\textit{Toán tử} 	$$ \Phi_ {P} (B^{s}) = 1-\Phi_{1}  B^{s} -\Phi_{2}  B^{2s}-...- \Phi_{P}  B^{s}$$
	và
	$$\varTheta_{Q}(B^{s})= 1+ \varTheta_{1}B^{s} + \varTheta_{2}B^{2s}+...+ \varTheta_{Q}B^{Qs}$$
	là toán tử tự phát theo mùa và toán tử trung bình trượt theo mùa của các order $P$ và $Q$, tương ứng, với thời gian $s$ theo mùa.
\end{dn}
Tương tự như các đặc tính của các mô hình ARMA không theo mùa, ARMA theo mùa thuần túy $(P, Q)$ là nguyên nhân chỉ khi căn của $\Phi_ {P} (z^{s})$ nằm cạnh ngoài vòng tròn đơn vị(>1), và nó khả nghịch chỉ khi căn của $\varTheta_{Q}(z^{s})$ nằm cạnh ngoài vòng tròn đơn vị (>=1)

Nói chung, chúng ta có thể kết hợp các toán tử theo mùa và không theo mùa thành mô hình SARIMA nhân, được ký hiệu là ARMA $(p, q)\times (P, Q)$ và viết
$$\Phi_ {P} (B^{s})\phi(B)x_{t}= \varTheta_{Q}(B^{s})\theta(B)w_{t}$$
như mô hình tổng thể. Mặc dù các thuộc tính được dự đoán trong Bảng 3.2 không đúng ngặt đối với mô hình hỗn hợp tổng thể, hành vi của ACF và PACF có xu hướng hiển thị các mẫu thô của mẫu được chỉ định. Trong thực tế, đối với các mô hình hỗn hợp, chúng ta có xu hướng thấy một hỗn hợp các sự kiện được liệt kê trong Bảng 3.1 và 3.2. Trong các mô hình thích hợp đó, việc tập trung vào các thành phần trung bình tự phát và di chuyển theo mùa đầu tiên thường dẫn đến kết quả khả quan hơn..

Sự không ổn định theo mùa có thể xảy ra, ví dụ, khi quá trình gần như định kỳ trong mùa. Ví dụ, với nhiệt độ trung bình hàng tháng qua các năm, mỗi tháng một sẽ xấp xỉ như nhau, mỗi tháng hai sẽ xấp xỉ như nhau, v.v. Trong trường hợp này, chúng tôi có thể nghĩ rằng nhiệt độ trung bình hàng tháng $x_{t}$ được mô hình hóa là
$$x_{t}=S_{t} +w_{t}$$
Trong đó $S_{t}$ là một thành phần theo mùa thay đổi chậm từ năm này sang năm khác, theo một bước ngẫu nhiên
$$ S_{t}=S_{t-12}+ v_{t}$$
Trong mô hình này, $w_{t}$ và $v_{t}$ là các nhiễu trắng không tương thích. Xu hướng dữ liệu tuân theo loại mô hình này sẽ được thể hiện trong một ACF mẫu lớn và phân rã rất chậm với độ trễ $h = 12k$, với $k = 1, 2, ....$ Nếu chúng ta bỏ đi ảnh hưởng của những năm liên tiếp với nhau, chúng ta thấy rằng
$$(1-B^{12})x_{t}=x_{t}-x_{t-12}=v_{t}+w_{t}-w_{t-12}$$
Mô hình này là $MA(1)_{12}$ cố định và ACF của nó sẽ chỉ có cực đại ở độ trễ 12. Nói chung, sự khác biệt theo mùa có thể được chỉ định khi ACF phân rã chậm ở bội số của mùa, nhưng không đáng kể giữa các giai đoạn. Sau đó, sự khác biệt theo mùa của order $D$ được định nghĩa là
$$\bigtriangledown_{s}^{D}x_{t}=(1-B^{s})^{D}x_{t},$$
trong đó $D = 1, 2, ...$ lấy các giá trị nguyên. Thông thường, $D = 1$ là đủ để có được sự ổn định theo mùa.

Kết hợp những ý tưởng này vào một mô hình chung dẫn đến định nghĩa sau.
\begin{dn}	
	\textit{Mô hình SARIMA, của Box và Jenkins (1970) được đưa ra bởi} 
	$$\Phi_ {P} (B^{s})	\phi(B)\bigtriangledown_{s}^{D}\bigtriangledown^{d}x_{t}=\alpha + \varTheta_{Q}(B^{s})\theta(B)w_{t}$$
	Trong đó $w_{t}$ là nhiễu trắng Gaussian thông thường. Mô hình chung được ký hiệu là ARIMA $(p, d, q) \times (P, D, Q )_{s}$ . Các thành phần trung bình tự động và trượt thông thường được biểu thị bằng đa thức $\phi(B)$ và $\theta(B)$ của các order $p$ và $q$, tương ứng [xem (3.5) và (3.17)],
	là toán tử tự phát theo mùa và toán tử trung bình trượt theo mùa của $\Phi_ {P} (B^{s})$ và $\varTheta_{Q}(B^{s})$ [xem (3.140) và (3.141)] của các order $P$ và $Q$, và các thành phần chênh lệch thông thường và theo mùa bởi $\bigtriangledown^{d}=(1-B)^{d}$ và $\bigtriangledown^{D}_{s}=(1-B^{s})^{D}$
\end{dn}
Chọn mô hình thích hợp cho một tập hợp dữ liệu nhất định từ tất cả các dữ liệu được biểu thị bằng biểu mẫu chung (3.144) là một nhiệm vụ khó khăn và chúng tôi thường nghĩ đầu tiên về việc tìm các toán tử vi phân tạo ra một chuỗi gần đúng và sau đó tìm kiếm một tập hợp đơn giản trung bình tự động hoặc nhân theo mùa ARMA để phù hợp với chuỗi dư kết quả. Các toán tử vi phân bậc 1được áp dụng, và sau đó phần dư được xây dựng từ một loạt chiều dài giảm.
\section*{Kết luận chương 1}
Trong chương 1, chúng tôi đã.....

\chapter{Thực hành phân tích chuỗi thời gian với phần mềm R}

Mục đích của chương này là trình bày các.......
\section{Tổng quan về phần mềm R và các gói lệnh cơ bản}

Nói một cách ngắn gọn, R là một phần mềm sử dụng cho phân tích thống kê và đồ thị. Thật ra, về bản chất, R là ngôn ngữ máy tính đa năng, có thể sử dụng cho nhiều mục tiêu khác nhau, từ tính toán đơn giản, toán học giải trí (recreational mathematics), tính toán ma trận, đến các phân tích thống kê phức tạp. Hơn thế nữa, nó cho phép bạn xây dựng những hàm, những câu lệnh chỉ để giải quyết một nhóm các nhiệm vụ phân tích đặc thù nào đó và chia sẻ chúng trên mạng. Chẳng hạn, nếu có một kiểm định mới, một mô hình mới về phương diện lý thuyết và được đăng trên một tạp chí chuyên nghành nào đó, bạn hoàn toàn có thể viết một chương trình nhằm biến kiểm định mới, những mô hình mới chỉ ở dạng lý thuyết kia thành một hàm cụ thể trong R. Nếu được kiểm tra bởi cộng đồng những người sử dụng rằng đúng và không có lỗi, hàm mà bạn viết sẽ được thừa nhận và sử dụng rộng rãi. Vì là một ngôn ngữ, cho nên người ta có thể sử dụng R để phát triển thành các phần mềm chuyên môn cho một vấn đề tính toán cá biệt.

Hai người sáng tạo ra R là hai nhà thống kê học tên là Ross Ihaka và Robert Gentleman. Kể từ khi R ra đời, rất nhiều nhà nghiên cứu thống kê và toán học trên thế giới ủng hộ và tham gia vào việc phát triển R. Chủ trương của những người sáng tạo ra R là theo định hướng mở rộng (Open Access). Cũng một phần vì chủ trương này mà R hoàn toàn miễn phí. Bất cứ ai ở bất cứ nơi nào trên thế giới đều có thể truy nhập và tải toàn bộ mã nguồn của R về máy tính của mình để sử dụng. Cho đến nay, chỉ qua chưa đầy 5 năm phát triển, nhưng có nhiều nhà thống kê học, toán học, nghiên cứu mọi lĩnh vực đã chuyển sang sử dụng R để phân tích dữ liệu khoa học. Trên toàn cầu, đã có một mạng lưới gần một triệu người sử dụng R, và con số này đang tăng theo cấp số nhân. Có thể nói trong 10 năm nữa, chúng ta sẽ không cần đến các phần mềm thống kê đắt tiền nhưu SAS, SPSS hay Stata (các phần mềm này giá có thể lên đến 100.000 USD một năm) để phần tích thống kê nữa, vì tất cả các phân tích đó có thể tiến hành bằng R.

Vì thế, chúng tôi đã chọn R để phân tích dữ liệu cho bài nghiên cứu khoa học này.
\subsection*{Một số gói lệnh cơ bản của R được sử dụng trong bài nghiên cứu}

R cung cấp cho chúng ta một “ngôn ngữ” máy tính và một số \textit{function} để làm các phân tích căn bản và đơn giản. Nếu muốn làm những phân tích phức tạp hơn, chúng ta cần phải tải về máy tính một số package khác. Package là một phần mềm nhỏ được các nhà thống kê phát triển để giải quyết một số vấn đề cụ thệ, và nó có thể chạy trong hệ thống R. Các package này cần phải được tải về máy tính và cài cặt.

Địa chỉ để tải các package vẫn là: \textit{http://cran.r-project.org}, rồi bấm vào phần “Packages” xuất hiện bên trái của mục lục trang web. Mốt số package cần tải về máy tính để sử dụng cho các ví dụ trong sách này là: 
\begin{center}
	\begin{tabular}{ |c|c|}
		\hline
		TÊN PACKAGE& CHỨC NĂNG\\
		\hline
		tseries & .......................................................\\
		forecast & ......................................................  \\
		abcxyz & .........................................................\\
		\hline
	\end{tabular}
\end{center}
\section{Dự báo lượng mưa tại trạm quan trắc Quy Nhơn}
Các thông tin dự báo khí hậu, đặc biệt là dự báo mưa mùa có ý nghĩa lớn đến các hoạt động phát triển kinh tế xã hội như: kế hoạch sản xuất nông nghiệp, du lịch, đánh bắt và nuôi trồng thủy sản, quản lý, khai thác có hiệu quả nguồn tài nguyên nước... Mức độ tin cậy về dự báo mưa mùa thường thấp hơn so với các yếu tố dự báo khác, nguyên nhân là do sự phân bố theo không gian và sự biến đổi theo thời gian của lượng mưa phụ thuộc vào nhiều yếu tố khác. Chính vì vậy công tác nghiên cứu dự báo mưa mùa tuy không còn mới nhưng vẫn đang rất được quan tâm ở nhiều nước trên thế giới, trong đó có Việt Nam.

Các nghiên cứu về lượng mưa trên thế giới ..................

Các nghiên cứu về lượng mưa ở trong nước ...................

\begin{nx}
Từ tổng quan nghiên cứu trong và ngoài nước về dự báo khí hậu, chúng tôi thấy ...................
Mô hình ARIMA................................
\end{nx}
\subsection*{Xây dựng mô hình dự báo lượng mưa ở Quy Nhơn bằng mô hình ARIMA}

\section{Dự báo số ca nhiễm mới virus COVID-19}
Trong bối cảnh virus corona chủng mới (COVID-19) đang lây lan khắp thế giới, việc dự báo số ca nhiễm bệnh và đỉnh điểm của dịch cao nhất khi nào là rất quan trọng. Trong phần này, chúng tôi sẽ dự đoán số ca nhiễm virus trên toàn thế giới bằng cách sử dụng mô hình ARIMA kết hợp với phần mềm R để đưa ra cho các quan chức y tế một ý tưởng tốt hơn về việc các dịch bệnh có thể phát triển nhanh đến mức nào và lây lan bao xa.

\subsection*{Xây dựng mô hình dự báo số ca nhiễm mới của virus COVID-19  bằng mô hình ARIMA}
\section*{Kết luận chương 2}
Trong chương này, chúng tôi đã trình bày ..............

\chapter*{Thảo luận}
\chapter*{Kết luận và kiến nghị} 

Trong đề tài này chúng tôi đã đạt đước các kết quả sau:
\begin{enumerate}[(1)]
	\item
	.........................................
	\item
	.........................................
\end{enumerate} 
\begin{thebibliography}{99}
	\addcontentsline{toc}{section}{{\bf Tài liệu tham khảo}\rm }
	\bibitem{1} .......
	\bibitem{2} .......
\end{thebibliography}

\end{document}
